
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "examples/19_local_datasource.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_examples_19_local_datasource.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_19_local_datasource.py:


Creating a Local Data Source
============================

Create and save an offline dataset to use in an inference pipeline.

This example demonstrates how to:

- Build a small offline dataset by fetching data and writing to a Zarr store
- Load the local store as a data source for an inference pipeline with the Microsoft Aurora model
- Run the deterministic workflow and plot results

.. GENERATED FROM PYTHON SOURCE LINES 30-37

.. code-block:: Python

    # /// script
    # dependencies = [
    #   "earth2studio[aurora] @ git+https://github.com/NVIDIA/earth2studio.git",
    #   "cartopy",
    # ]
    # ///


.. GENERATED FROM PYTHON SOURCE LINES 38-44

Set Up
------
For this example, the following are needed:

- Prognostic Model: Use the built-in Aurora 6-hour model :py:class:`earth2studio.models.px.Aurora`.
- Data source: Pull data from the WeatherBench2 data API :py:class:`earth2studio.data.WB2ERA5`.

.. GENERATED FROM PYTHON SOURCE LINES 46-63

.. code-block:: Python

    import os

    os.makedirs("outputs", exist_ok=True)
    from dotenv import load_dotenv

    load_dotenv()

    from earth2studio.data import WB2ERA5, fetch_data
    from earth2studio.models.px import Aurora

    # Load the default model package which downloads the checkpoint from GCP
    package = Aurora.load_default_package()
    model = Aurora.load_model(package)

    # Create the data source, cache is false
    wb2 = WB2ERA5(cache=False, verbose=False)


.. GENERATED FROM PYTHON SOURCE LINES 64-72

Creating a Local Zarr Store from a Datasource
---------------------------------------------
Start with creating a local dataset from the WeatherBench2 data store. Since data
sources return in-memory data arrays, there are a variety of ways this could be done.
The following is a simple method using Earth2Studio IO objects to pack the requested
data into a single Zarr store.

For this example, let's download some data for a Microsoft aurora forecast.

.. GENERATED FROM PYTHON SOURCE LINES 74-110

.. code-block:: Python

    from collections import OrderedDict

    import numpy as np

    from earth2studio.io import ZarrBackend
    from earth2studio.utils.coords import split_coords

    times = np.array(
        [np.datetime64("2022-01-01T00:00:00"), np.datetime64("2022-01-01T06:00:00")]
    )
    variables = model.input_coords()["variable"]
    zarr_path = "./outputs/19_wb2_dataset.zarr"
    # Create Zarr store to pack data into
    zb = ZarrBackend(file_name=zarr_path, backend_kwargs={"overwrite": True})
    full_coords = OrderedDict(
        [
            ("time", np.atleast_1d(times)),
            ("lead_time", np.array([np.timedelta64(0, "h")])),
            ("lat", np.linspace(90, -90, 721)),
            ("lon", np.linspace(0, 359.75, 1440)),
        ]
    )
    zb.add_array(full_coords, array_name=list(variables))

    # Loop over timestamps, fetch data and write slices into the pre-created arrays
    for t in np.atleast_1d(times):
        x, coords = fetch_data(
            wb2,
            time=np.array([t]),
            variable=variables,
            lead_time=np.array([np.timedelta64(0, "h")]),
            device="cpu",
        )
        xs, reduced_coords, var_names = split_coords(x, coords, dim="variable")
        zb.write(xs, reduced_coords, array_name=list(var_names))


.. GENERATED FROM PYTHON SOURCE LINES 111-114

Note that the Zarr store we just created can be used for more than just Earth2Studio
inference pipelines. Open it with zarr or xarray to explore/process what
you just downloaded.

.. GENERATED FROM PYTHON SOURCE LINES 116-121

.. code-block:: Python

    import zarr

    zg = zarr.group(store=zarr.storage.LocalStore(zarr_path))
    print(zg.tree())


.. GENERATED FROM PYTHON SOURCE LINES 122-131

Execute the Workflow
--------------------
To use the saved dataset as a data source, we could create our own class that implements
the interface required by :py:class:`earth2studio.data.base.DataSource`, which needs
just a ``__call__(time, variable)`` method.

However, since we used an IO backend from Earth2Studio we can use the
:py:class:`earth2studio.data.xr.InferenceOutputSource` which is a convenience class
that supports the output of inference pipelines.

.. GENERATED FROM PYTHON SOURCE LINES 133-148

.. code-block:: Python

    import earth2studio.run as run
    from earth2studio.data import InferenceOutputSource

    offline_source = InferenceOutputSource(zarr_path)
    out_zarr_path = "./outputs/19_pangu_output.zarr"
    io = ZarrBackend(file_name=out_zarr_path, backend_kwargs={"overwrite": True})
    io = run.deterministic(
        times[-1:],
        4,
        model,
        offline_source,
        io,
        output_coords=OrderedDict({"variable": np.array(["msl"])}),
    )


.. GENERATED FROM PYTHON SOURCE LINES 149-152

Post Processing
---------------
The last step is to post-process our results.

.. GENERATED FROM PYTHON SOURCE LINES 152-186

.. code-block:: Python


    import cartopy.crs as ccrs
    import matplotlib.pyplot as plt

    plt.close("all")
    projection = ccrs.Robinson()
    fig, axes = plt.subplots(
        2,
        2,
        subplot_kw={"projection": projection},
        figsize=(12, 7),
        constrained_layout=True,
    )
    axes = axes.ravel()

    lon = io["lon"][:]
    lat = io["lat"][:]
    lead_steps = [1, 2, 3, 4]  # 6h, 12h, 18h, 24h
    for ax, step in zip(axes, lead_steps):
        im = ax.pcolormesh(
            lon,
            lat,
            io["msl"][0, step],
            transform=ccrs.PlateCarree(),
            cmap="PiYG",
        )
        ax.set_title(f"msl - Lead time: {6*step}h")
        ax.coastlines()
        ax.gridlines(draw_labels=False)

    fig.colorbar(
        im, ax=axes, orientation="horizontal", fraction=0.05, pad=0.07, label="msl"
    )
    plt.savefig("outputs/19_msl_1day.png", dpi=150)


.. _sphx_glr_download_examples_19_local_datasource.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: 19_local_datasource.ipynb <19_local_datasource.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: 19_local_datasource.py <19_local_datasource.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: 19_local_datasource.zip <19_local_datasource.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
