{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Extending Prognostic Models\n\nImplementing a custom prognostic model\n\nThis example will demonstrate how to extend Earth2Studio by implementing a custom\nprognostic model and running it in a general workflow.\n\nIn this example you will learn:\n\n- API requirements of prognostic models\n- Implementing a custom prognostic model\n- Running this model in existing workflows\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom Prognostic\nAs discussed in the `prognostic_model_userguide` section of the user guide,\nEarth2Studio defines a prognostic model through a simple interface\n:py:class:`earth2studio.models.px.base.PrognosticModel`. This can be used to help\nguide the required APIs needed to successfully create our own custom prognostic.\n\nIn this example, let's create a simple prognostic that simply predicts adds normal\nnoise to the surface wind fields every time-step. While not practical, this should\ndemonstrate the APIs one needs to implement for any prognostic.\n\nStarting with the constructor, prognostic models should typically be torch modules.\nModels need to have a :py:obj:`to(device)` method that can move the model between\ndifferent devices. If your model is PyTorch, then this will be easy.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\nfrom typing import Generator, Iterator\n\nimport numpy as np\nimport torch\n\nfrom earth2studio.models.batch import batch_func\nfrom earth2studio.utils import handshake_coords, handshake_dim\nfrom earth2studio.utils.type import CoordSystem\n\n\nclass CustomPrognostic(torch.nn.Module):\n    \"\"\"Custom prognostic model\"\"\"\n\n    def __init__(self, noise_amplitude: float = 0.1):\n        super().__init__()\n        self.amp = noise_amplitude\n\n    input_coords = OrderedDict(\n        {\n            \"batch\": np.empty(0),\n            \"lead_time\": np.array([np.timedelta64(0, \"h\")]),\n            \"variable\": np.array([\"u10m\", \"v10m\"]),\n            \"lat\": np.linspace(90, -90, 721),\n            \"lon\": np.linspace(0, 360, 1440, endpoint=False),\n        }\n    )\n\n    output_coords = OrderedDict(\n        {\n            \"batch\": np.empty(0),\n            \"lead_time\": np.array([np.timedelta64(1, \"h\")]),\n            \"variable\": np.array([\"u10m\", \"v10m\"]),\n            \"lat\": np.linspace(90, -90, 721),\n            \"lon\": np.linspace(0, 360, 1440, endpoint=False),\n        }\n    )\n\n    @batch_func()\n    def __call__(\n        self,\n        x: torch.Tensor,\n        coords: CoordSystem,\n    ) -> tuple[torch.Tensor, CoordSystem]:\n        \"\"\"Runs prognostic model 1 step.\n\n        Parameters\n        ----------\n        x : torch.Tensor\n            Input tensor\n        coords : CoordSystem\n            Input coordinate system\n        \"\"\"\n        for i, (key, value) in enumerate(self.input_coords.items()):\n            if key != \"batch\":\n                handshake_dim(coords, key, i)\n                handshake_coords(coords, self.input_coords, key)\n\n        out_coords = coords.copy()\n        out_coords[\"lead_time\"] = self.output_coords[\"lead_time\"]\n        out = x + self.amp * torch.rand_like(x)\n\n        return out, out_coords\n\n    @batch_func()\n    def _default_generator(\n        self, x: torch.Tensor, coords: CoordSystem\n    ) -> Generator[tuple[torch.Tensor, CoordSystem], None, None]:\n        \"\"\"Create prognostic generator\"\"\"\n        coords = coords.copy()\n\n        for i, (key, value) in enumerate(self.input_coords.items()):\n            if key != \"batch\":\n                handshake_dim(coords, key, i)\n                handshake_coords(coords, self.input_coords, key)\n\n        # First time-step should always be the initial state\n        yield x, coords\n\n        out_coords = coords.copy()\n        while True:\n            out_coords[\"lead_time\"] += self.output_coords[\"lead_time\"]\n            x = x + self.amp * torch.randn_like(x)\n            yield x, out_coords\n\n    def create_iterator(\n        self, x: torch.Tensor, coords: CoordSystem\n    ) -> Iterator[tuple[torch.Tensor, CoordSystem]]:\n        \"\"\"Creates a iterator which can be used to perform time-integration of the\n        prognostic model. Will return the initial condition first (0th step).\n\n        Parameters\n        ----------\n        x : torch.Tensor\n            Input tensor\n        coords : CoordSystem\n            Input coordinate system\n        \"\"\"\n\n        yield from self._default_generator(x, coords)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Input/Output Coordinates\nDefining the input/output coordinate systems is essential for any model in\nEarth2Studio since this is how both the package and users can learn what type of data\nthe model expects. Have a look at `coordinates_userguide` for details on\ncoordinate system. Here, we define the input output coords to be the surface winds\nand give the model a time-step size of 1 hour.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### :py:func:`__call__` API\nThe call function is one of the two main APIs used to interact with the prognostic\nmodel. The first thing we do is check the coordinate system of the input data is indeed\nwhat the model expects. Next, we execute the forward pass of our model (apply noise)\nand then update the output coordinate system.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>You may notice the :py:func:`batch_func` decorator, which is used to make batched\n  operations easier. For more details about this refer to the `batch_function_userguide`\n  section of the user guide.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### :py:func:`create_iterator` API\nThe call function is useful for a single time-step. However, prognostics generate\ntime-series which is done using an iterator. This is achieved by creating a generator\nunder the hood of the prognostic.\n\nA generator in Python is essentially a function that returns an iterator using the\n:py:obj:`yield` keyword. In the case of prognostics, it yields a single time-step\nprediction of the model. Note that this allows the model to control its own internal\nstate inside the iterator independent of the workflow.\n\nSince this model is auto regressive, it can theoretically index in time forever. Thus,\nwe make the generator an infinite loop. Keep in mind that generators execute on\ndemand, so this infinite loop won't cause the program to get stuck.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Up\nWith the custom prognostic defined, it's now easily usable in a standard workflow. In\nthis example, we will use the build in workflow :py:meth:`earth2studio.run.deterministic`.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's instantiate the components needed.\n\n- Prognostic Model: Use our custom prognostic defined above.\n- Datasource: Pull data from the GFS data api :py:class:`earth2studio.data.GFS`.\n- IO Backend: Save the outputs into a Zarr store :py:class:`earth2studio.io.ZarrBackend`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n\nimport numpy as np\nfrom dotenv import load_dotenv\n\nload_dotenv()  # TODO: make common example prep function\n\nfrom earth2studio.data import GFS\nfrom earth2studio.io import ZarrBackend\n\n# Create the prognostic\nmodel = CustomPrognostic(noise_amplitude=10.0)\n\n# Create the data source\ndata = GFS()\n\n# Create the IO handler, store in memory\nio = ZarrBackend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Execute the Workflow\nBecause the prognostic meets the needs of the interface, the workflow will execute\njust like any other model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import earth2studio.run as run\n\nnsteps = 24\nio = run.deterministic([\"2024-01-01\"], nsteps, model, data, io)\n\nprint(io.root.tree())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Post Processing\nTo confirm that our prognostic model is working as expected, we should see the fields\nbecome progressively more noisy as time progresses.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n\nos.makedirs(\"outputs\", exist_ok=True)\nimport matplotlib.pyplot as plt\n\nforecast = \"2024-01-01\"\nvariable = \"u10m\"\n\nplt.close(\"all\")\n\n# Create a figure and axes with the specified projection\nfig, ax = plt.subplots(2, 2, figsize=(6, 4))\n\n# Plot u10m every 6 hours\nax[0, 0].imshow(io[variable][0, 0], vmin=-20, vmax=20)\nax[0, 1].imshow(io[variable][0, 6], vmin=-20, vmax=20)\nax[1, 0].imshow(io[variable][0, 12], vmin=-20, vmax=20)\nax[1, 1].imshow(io[variable][0, 18], vmin=-20, vmax=20)\n\n\n# Set title\nplt.suptitle(f\"{variable} - {forecast}\")\ntimes = io[\"lead_time\"].astype(\"timedelta64[h]\").astype(int)\nax[0, 0].set_title(f\"Lead time: {times[0]}hrs\")\nax[0, 1].set_title(f\"Lead time: {times[6]}hrs\")\nax[1, 0].set_title(f\"Lead time: {times[12]}hrs\")\nax[1, 1].set_title(f\"Lead time: {times[18]}hrs\")\n\nplt.savefig(\"outputs/custom_prognostic_prediction.jpg\", bbox_inches=\"tight\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}