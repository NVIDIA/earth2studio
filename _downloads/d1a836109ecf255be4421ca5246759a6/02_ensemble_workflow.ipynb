{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Running Ensemble Inference\n\nSimple ensemble inference workflow.\n\nThis example will demonstrate how to run a simple inference workflow to generate a\nsimple ensemble forecast using one of the built in models of Earth-2 Inference\nStudio.\n\nIn this example you will learn:\n\n- How to instantiate a built in prognostic model\n- Creating a data source and IO object\n- Select a perturbation method\n- Running a simple built in workflow\n- Extend a built-in method using custom code.\n- Post-processing results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating a Simple Ensemble Workflow\n\nTo start lets begin with creating a simple ensemble workflow to use. We encourage\nusers to explore and experiment with their own custom workflows that borrow ideas from\nbuilt in workflows inside :py:obj:`earth2studio.run` or the examples.\n\nCreating our own generalizable ensemble workflow is easy when we rely on the component\ninterfaces defined in Earth2Studio (use dependency injection). Here we create a run\nmethod that accepts the following:\n\n- time: Input list of datetimes / strings to run inference for\n- nsteps: Number of forecast steps to predict\n- nensemble: Number of ensembles to run for\n- prognostic: Our initialized prognostic model\n- perturbation_method: Our initialized pertubation method\n- data: Initialized data source to fetch initial conditions from\n- io: IOBackend\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\nfrom typing import Optional\nfrom dotenv import load_dotenv\n\nload_dotenv()  # TODO: make common example prep function\n\nimport numpy as np\nimport torch\nfrom loguru import logger\nfrom tqdm import tqdm\n\nfrom earth2studio.data import DataSource, fetch_data\nfrom earth2studio.io import IOBackend\nfrom earth2studio.models.px import PrognosticModel\nfrom earth2studio.perturbation import PerturbationMethod\nfrom earth2studio.utils.coords import map_coords, extract_coords\nfrom earth2studio.utils.time import to_time_array\n\nlogger.remove()\nlogger.add(lambda msg: tqdm.write(msg, end=\"\"), colorize=True)\n\n\ndef run_ensemble(\n    time: list[str] | list[datetime] | list[np.datetime64],\n    nsteps: int,\n    nensemble: int,\n    prognostic: PrognosticModel,\n    perturbation_method: PerturbationMethod,\n    data: DataSource,\n    io: IOBackend,\n) -> IOBackend:\n    \"\"\"Simple ensemble workflow\n\n    Parameters\n    ----------\n    time : list[str] | list[datetime] | list[np.datetime64]\n        List of string, datetimes or np.datetime64\n    nsteps : int\n        Number of forecast steps\n    nensemble : int\n        Number of ensemble members to run inference for.\n    prognostic : PrognosticModel\n        Prognostic models\n    perturbation_method : PerturbationMethod\n        Method of perturbing the initial condition to form an ensemble.\n    data : DataSource\n        Data source\n    io : IOBackend\n        IO object\n\n    Returns\n    -------\n    IOBackend\n        Output IO object\n    \"\"\"\n    logger.info(\"Running simple workflow!\")\n    # Load model onto the device\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    logger.info(f\"Inference device: {device}\")\n    prognostic = prognostic.to(device)\n    # Fetch data from data source and load onto device\n    time = to_time_array(time)\n    x, coords = fetch_data(\n        source=data,\n        time=time,\n        variable=prognostic.input_coords[\"variable\"],\n        device=device,\n    )\n    logger.success(f\"Fetched data from {data.__class__.__name__}\")\n\n    # Expand x, coords for ensemble\n    x = x.unsqueeze(0).repeat(nensemble, *([1] * x.ndim))\n    coords = {\"ensemble\": np.arange(nensemble)} | coords\n\n    # Set up IO backend\n    total_coords = coords.copy()\n    total_coords[\"lead_time\"] = np.asarray(\n        [\n            coords[\"lead_time\"] + prognostic.output_coords[\"lead_time\"] * i\n            for i in range(nsteps + 1)\n        ]\n    ).flatten()\n\n    var_names = total_coords.pop(\"variable\")\n    io.add_array(total_coords, var_names)\n\n    # Map lat and lon if needed\n    x, coords = map_coords(x, coords, prognostic.input_coords)\n\n    # Perturb ensemble\n    x += perturbation_method(x, coords)\n\n    # Create prognostic iterator\n    model = prognostic.create_iterator(x, coords)\n\n    logger.info(\"Inference starting!\")\n    with tqdm(total=nsteps + 1, desc=\"Running inference\") as pbar:\n        for step, (x, coords) in enumerate(model):\n            io.write(*extract_coords(x, coords))\n            pbar.update(1)\n            if step == nsteps:\n                break\n\n    logger.success(\"Inference complete\")\n    return io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Up\nWith the ensemble workflow defined, we now need to create the indivdual components.\n\nWe need the following:\n\n- Prognostic Model: Use the built in FourCastNet model :py:class:`earth2studio.models.px.FCN`.\n- perturbation_method: Use the Spherical Gaussian Method :py:class:`earth2studio.perturbation.SphericalGaussian`.\n- Datasource: Pull data from the GFS data api :py:class:`earth2studio.data.GFS`.\n- IO Backend: Lets save the outputs into a Zarr store :py:class:`earth2studio.io.ZarrBackend`.\n\n%%\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport torch\nfrom collections import OrderedDict\nfrom typing import Union, List\n\nfrom earth2studio.models.px import FCN\nfrom earth2studio.perturbation import PerturbationMethod, SphericalGaussian\nfrom earth2studio.data import GFS\nfrom earth2studio.io import ZarrBackend\nfrom earth2studio.utils.type import CoordSystem\n\n# Load the default model package which downloads the check point from NGC\npackage = FCN.load_default_package()\nmodel = FCN.load_model(package)\n\n# Instantiate the pertubation method\nsg = SphericalGaussian(noise_amplitude=0.05)\n\n# Create the data source\ndata = GFS()\n\n# Create the IO handler, store in memory\nchunks = {\"ensemble\": 1, \"time\": 1}\nio = ZarrBackend(file_name=\"outputs/ensemble_sg.zarr\", chunks=chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Part I focuses on using existing methods in the ensemble workflow. In part II, we will\nshow how one can extend the existing perturbation method.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Execute the Workflow\nWith all componments intialized, running the workflow is a single line of Python code.\nWorkflow will return the provided IO object back to the user, which can be used to\nthen post process. Some have additional APIs that can be handy for post-processing or\nsaving to file. Check the API docs for more information.\n\nFor the forecast we will predict for two days (these will get executed as a batch) for\n20 forecast steps which is 5 days.\n%%\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "nsteps = 10\nnensemble = 8\nio = run_ensemble([\"2024-01-01\"], nsteps, nensemble, model, sg, data, io)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Post Processing\nThe last step is to post process our results. Cartopy is a greate library for plotting\nfields on projects of a sphere.\n\nNotice that the Zarr IO function has additional APIs to interact with the stored data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\nfrom matplotlib.colors import TwoSlopeNorm\n\nforecast = \"2024-01-01\"\nvariable = \"t2m\"\nstep = 0  # lead time = 24 hrs\n\nplt.close(\"all\")\n# Create a Robinson projection\nprojection = ccrs.Robinson()\n\n# Create a figure and axes with the specified projection\nfig, (ax1, ax2, ax3) = plt.subplots(\n    nrows=1, ncols=3, subplot_kw={\"projection\": projection}, figsize=(12, 5)\n)\n\n\ndef plot_(axi, data, title):\n    \"\"\"Convenience function for plotting pcolormesh.\"\"\"\n    # Plot the field using pcolormesh\n    im = axi.pcolormesh(\n        io[\"lon\"][:],\n        io[\"lat\"][:],\n        data,\n        transform=ccrs.PlateCarree(),\n        cmap=\"coolwarm\",\n    )\n    plt.colorbar(im, ax=axi)\n    # Set title\n    axi.set_title(title)\n    # Add coastlines and gridlines\n    axi.coastlines()\n    axi.gridlines()\n\n\nplot_(\n    ax1,\n    io[variable][0, 0, step],\n    f\"{forecast} - Lead time: {6*step}hrs - Member: {0}\",\n)\nplot_(\n    ax2,\n    io[variable][1, 0, step],\n    f\"{forecast} - Lead time: {6*step}hrs - Member: {1}\",\n)\nplot_(\n    ax3,\n    np.std(io[variable][:, 0, step], axis=0),\n    f\"{forecast} - Lead time: {6*step}hrs - Std\",\n)\n\nplt.savefig(f\"outputs/02_{forecast}_{variable}_{step}_ensemble.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The perturbation method in part I is naive because it applies the same noise amplitude\nto every variable. We can create a custom wrapper that only applies the perturbation\nmethod to a particular variable instead.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class ApplyToVariable:\n    \"\"\"Apply a perturbation to only a particular variable.\"\"\"\n\n    def __init__(self, pm: PerturbationMethod, variable: Union[str, List[str]]):\n        self.pm = pm\n        if isinstance(variable, str):\n            variable = [variable]\n        self.variable = variable\n\n    @torch.inference_mode()\n    def __call__(\n        self,\n        x: torch.Tensor,\n        coords: CoordSystem,\n    ) -> torch.Tensor:\n        # Construct perturbation\n        dx = self.pm(x, coords)\n        # Find variable in data\n        ind_coord = list(coords).index(\"variable\")\n        ind = np.in1d(coords[\"variable\"], self.variable)\n        dx[..., ~ind, :, :] = 0.0\n        return dx\n\n\n# Generate a new noise amplitude that specifically targets 't2m' with a 1 K noise amplitude\navsg = ApplyToVariable(SphericalGaussian(noise_amplitude=1.0), \"t2m\")\n\n# Create the IO handler, store in memory\nio = ZarrBackend(file_name=\"outputs/ensemble_avsg.zarr\", chunks=chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Execute the Workflow\nWith all componments intialized, running the workflow is a single line of Python code.\nWorkflow will return the provided IO object back to the user, which can be used to\nthen post process. Some have additional APIs that can be handy for post-processing or\nsaving to file. Check the API docs for more information.\n\nFor the forecast we will predict for two days (these will get executed as a batch) for\n20 forecast steps which is 5 days.\n%%\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "nsteps = 10\nnensemble = 4\nio = run_ensemble([\"2024-01-01\"], nsteps, nensemble, model, avsg, data, io)\n\n# Post Processing\n# ---------------\n# The last step is to post process our results. Cartopy is a greate library for plotting\n# fields on projects of a sphere.\n#\n# Notice that the Zarr IO function has additional APIs to interact with the stored data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "forecast = \"2024-01-01\"\nvariable = \"tcwv\"\nstep = 0  # lead time = 24 hrs\n\nplt.close(\"all\")\n# Create a Robinson projection\nprojection = ccrs.Robinson()\n\n# Create a figure and axes with the specified projection\nfig, (ax1, ax2, ax3) = plt.subplots(\n    nrows=1, ncols=3, subplot_kw={\"projection\": projection}, figsize=(12, 5)\n)\nplot_(\n    ax1,\n    io[variable][0, 0, step],\n    f\"{forecast} - Lead time: {6*step}hrs - Member: {0}\",\n)\nplot_(\n    ax2,\n    io[variable][1, 0, step],\n    f\"{forecast} - Lead time: {6*step}hrs - Member: {1}\",\n)\nplot_(\n    ax3,\n    np.std(io[variable][:, 0, step], axis=0),\n    f\"{forecast} - Lead time: {6*step}hrs - Std\",\n)\n\nplt.savefig(f\"outputs/02_{forecast}_{variable}_{step}_ensemble_custom_perturb.jpg\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}