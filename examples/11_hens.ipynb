{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HENS\n",
    "\n",
    "First, some background info on HENS and that there's more to explore\n",
    "in the folder...\n",
    "\n",
    "Quite a few configs to be tweaked, so we will set the most important ones here\n",
    "and then turn them into a config opbject afterwards.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'helene'\n",
    "\n",
    "start_times = [\"2024-09-24 12:00:00\"]\n",
    "nsteps = 16\n",
    "nensemble = 4\n",
    "batch_size = 2\n",
    "\n",
    "model_packages = '/media/mkoch/9ee63bf8-5a14-4872-86f2-7f16b120269b/hens_data/hens_checkpoints'\n",
    "max_num_checkpoints = 2\n",
    "\n",
    "output_vars = [\"t2m\", 'u10m', 't850', 'q850', 'z500']\n",
    "out_dir = './outputs'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next, let's do some imports and fully configure the inference. for more detailed\n",
    "info about the configurations, see the README in the 11_hens folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import DictConfig\n",
    "from physicsnemo.distributed import DistributedManager\n",
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), '11_hens'))\n",
    "load_dotenv()\n",
    "DistributedManager.initialize()\n",
    "\n",
    "# Create the configuration dictionary\n",
    "cfg = DictConfig({\n",
    "    'project': project,\n",
    "    'random_seed': 377778,\n",
    "    'start_times': start_times,\n",
    "    'nsteps': nsteps,          # number of forecasting steps\n",
    "    'nensemble': nensemble,       # ensemble size per checkpoint\n",
    "    'batch_size': batch_size,      # inference batch size\n",
    "\n",
    "    'forecast_model': {\n",
    "        'architecture': 'earth2studio.models.px.SFNO',   # forecast model class\n",
    "        'package': model_packages,\n",
    "        'max_num_checkpoints': max_num_checkpoints  # max number of checkpoints which will be used\n",
    "    },\n",
    "\n",
    "    'data_source': {\n",
    "        '_target_': 'earth2studio.data.GFS'  # data source class\n",
    "    },\n",
    "\n",
    "    'cyclone_tracking': {\n",
    "        'out_dir': out_dir\n",
    "    },\n",
    "\n",
    "    'file_output': {\n",
    "        'path': out_dir,       # directory to which outfiles are written\n",
    "        'output_vars': output_vars,\n",
    "        'thread_io': False,      # write out in separate thread\n",
    "        'format': {              # io backend class\n",
    "            '_target_': 'earth2studio.io.NetCDF4Backend',\n",
    "            '_partial_': True,\n",
    "            'backend_kwargs': {\n",
    "                'mode': 'w',\n",
    "                'diskless': False,\n",
    "                'persist': False,\n",
    "                'chunks': {\n",
    "                    'ensemble': 1,\n",
    "                    'time': 1,\n",
    "                    'lead_time': 1\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- why is batch generation progress not shown? To be fixed (cursor knows how, but it isn't clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from ensemble_utilities import EnsembleBase\n",
    "from reproduce_utilities import create_base_seed_string\n",
    "\n",
    "from utilities import (\n",
    "    initialise,\n",
    "    initialise_output,\n",
    "    store_tracks,\n",
    "    update_model_dict,\n",
    "    write_to_disk,\n",
    ")\n",
    "\n",
    "(\n",
    "    ensemble_configs,\n",
    "    model_dict,\n",
    "    dx_model_dict,\n",
    "    cyclone_tracking,\n",
    "    data,\n",
    "    output_coords_dict,\n",
    "    base_random_seed,\n",
    "    all_tracks_dict,\n",
    "    _, _\n",
    ") = initialise(cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ensemble configs include XYZ and represent blah. Let's have a look at the content and explore how many cases we will run, depending on number of ensemble members, batch size, number of checkpoints and initial conditions.\n",
    "\n",
    "The inference is parallelised across enssemble config entries, hence across IC-package pairs. This also menas that you cannot use more GPUs than number of ICs multiplied by number of checkpoints. If more GPUs are available, they remain idle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii, (pkg, ic, ens_idx, batch_ids_produce) in enumerate(ensemble_configs):\n",
    "    print(f'ensemble config {ii+1} of {len(ensemble_configs)}:')\n",
    "    print(f'    package: {pkg}')\n",
    "    print(f'    initial condition: {ic}')\n",
    "    print(f'    ensemble index of first member: {ens_idx}')\n",
    "    print(f'    batch ids to produce: {batch_ids_produce}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model dict includes model and weights. Let's have a look at its contents. At each loop, it will be updated according to pkg in provided in the ensemble config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored\n",
    "\n",
    "print(colored('The model class is:', attrs=['bold']))\n",
    "print(model_dict['class'], '\\n')\n",
    "\n",
    "print(colored('The model package (weights), which is currently loaded:', attrs=['bold']))\n",
    "print(model_dict['package'], '\\n')\n",
    "\n",
    "print(colored('The fully initialised model is provided in:', attrs=['bold']))\n",
    "print(model_dict['model'].parameters, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to set up HENS perturbation.\n",
    "to see how it is aseembled form basic blocks porvided in e2studio, have a look into `11_hens/hens_perturbation.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for perturbation\n",
    "skill_path = \"/media/mkoch/9ee63bf8-5a14-4872-86f2-7f16b120269b/hens_data/hens_checkpoints/d2m_sfno_linear_74chq_sc2_layers8_edim620_wstgl2-epoch70_seed16.nc\"\n",
    "noise_amplification = 0.35\n",
    "perturbed_var = [\"z500\"]\n",
    "integration_steps = 3\n",
    "\n",
    "from hens_perturbation import HENSPerturbation\n",
    "\n",
    "from numpy import ndarray, datetime64\n",
    "\n",
    "from earth2studio.data import DataSource\n",
    "from earth2studio.models.px import PrognosticModel\n",
    "from earth2studio.perturbation import Perturbation\n",
    "\n",
    "def initialise_perturbation(\n",
    "    model: PrognosticModel,\n",
    "    data: DataSource,\n",
    "    start_time: ndarray[datetime64],\n",
    ") -> Perturbation:\n",
    "    perturbation = HENSPerturbation(\n",
    "        model=model,\n",
    "        data=data,\n",
    "        start_time=start_time,\n",
    "        skill_path=skill_path,\n",
    "        noise_amplification=noise_amplification,\n",
    "        perturbed_var=perturbed_var,\n",
    "        integration_steps=integration_steps\n",
    "    )\n",
    "\n",
    "    return perturbation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now bring everyhting together:\n",
    "- loop over ensemble configs\n",
    "- update model dict (if package has changed)\n",
    "- initialise output\n",
    "- initialise perturbation (as ICs might have changed)\n",
    "- run inference, where all ensemble members are produced\n",
    "- write to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over ensemble configs\n",
    "for pkg, ic, ens_idx, batch_ids_produce in ensemble_configs:\n",
    "    # create seed base string required for reproducibility of individual batches\n",
    "    base_seed_string = create_base_seed_string(pkg, ic, base_random_seed)\n",
    "\n",
    "    # load new weights if necessary\n",
    "    model_dict = update_model_dict(model_dict, pkg)\n",
    "\n",
    "    # create new io object\n",
    "    io_dict = initialise_output(cfg, ic, model_dict, output_coords_dict)\n",
    "\n",
    "    # initialise perturbation with updated IC and checkpoint\n",
    "    perturbation = initialise_perturbation(\n",
    "        model=model_dict[\"model\"], data=data, start_time=ic\n",
    "    )\n",
    "\n",
    "    # initialise inference pipeline with updated IC and checkpoint\n",
    "    run_hens = EnsembleBase(\n",
    "        time=[ic],\n",
    "        nsteps=cfg.nsteps,\n",
    "        nensemble=cfg.nensemble,\n",
    "        prognostic=model_dict[\"model\"],\n",
    "        data=data,\n",
    "        io_dict=io_dict,\n",
    "        perturbation=perturbation,\n",
    "        output_coords_dict=output_coords_dict,\n",
    "        dx_model_dict=dx_model_dict,\n",
    "        cyclone_tracking=cyclone_tracking,\n",
    "        batch_size=cfg.batch_size,\n",
    "        ensemble_idx_base=ens_idx,\n",
    "        batch_ids_produce=batch_ids_produce,\n",
    "        base_seed_string=base_seed_string,\n",
    "    )\n",
    "\n",
    "    # run inference\n",
    "    df_tracks_dict, io_dict = run_hens()\n",
    "\n",
    "    # store tracks\n",
    "    for k, v in df_tracks_dict.items():\n",
    "        v[\"ic\"] = pd.to_datetime(ic)\n",
    "        all_tracks_dict[k].append(v)\n",
    "\n",
    "    # if in-memory flavour of io backend was chosen, write content to disk now\n",
    "    if io_dict:\n",
    "        _, _ = write_to_disk(\n",
    "            cfg,\n",
    "            ic,\n",
    "            model_dict,\n",
    "            io_dict,\n",
    "            None,\n",
    "            None,\n",
    "        )\n",
    "\n",
    "# write cyclone tracks to disk\n",
    "if \"cyclone_tracking\" in cfg:\n",
    "    for area_name, all_tracks in all_tracks_dict.items():\n",
    "        store_tracks(area_name, all_tracks, cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, there should be a folder called \"output\" with all the forecasts.\n",
    "Also the tracks should be in there.\n",
    "\n",
    "plot tracks and fields.\n",
    "\n",
    "as we can see there are 4 members, one IC (time), 4 lead time in the field output\n",
    "\n",
    "track headers mean xyz...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from plotting.fork_n_spoon import extract_tracks_from_csv\n",
    "\n",
    "ds = xr.load_dataset('outputs/global/helene_2024-09-24T12_pkg_seed102.nc')\n",
    "display(ds)\n",
    "\n",
    "tracks = pd.read_csv('outputs/global/helene_tracks_rank_000.csv', sep=',')\n",
    "print('tracks columns:')\n",
    "print(list(tracks.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot global fields through:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['t2m'].isel(ensemble=0, lead_time=0, time=0).plot(figsize=(16, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's extract helene tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helene_ibtracs_coords = pd.DataFrame({\n",
    "    'time': pd.date_range('2024-09-21 18:00:00', '2024-09-28 12:00:00', freq='3h'),\n",
    "    'lat': [13.60, 13.80, 14.00, 14.20, 14.40, 14.60, 14.80, 15.00, 15.20, 15.40,\n",
    "            15.60, 15.70, 16.00, 16.60, 17.20, 17.60, 17.90, 18.10, 18.20, 18.40,\n",
    "            18.60, 19.00, 19.30, 19.40, 19.40, 19.50, 19.80, 20.00, 20.30, 20.70,\n",
    "            21.10, 21.50, 22.00, 22.40, 22.80, 23.20, 23.60, 24.10, 24.70, 25.60,\n",
    "            26.70, 27.70, 28.70, 29.90, 31.30, 32.90, 34.40, 35.70, 36.70, 37.60,\n",
    "            38.10, 37.90, 37.40, 37.00, 36.60],\n",
    "    'lon': [277.3, 277.4, 277.4, 277.4, 277.4, 277.4, 277.4, 277.4, 277.4,\n",
    "            277.4, 277.5, 277.7, 278. , 278.1, 278.2, 278.2, 278.1, 278. ,\n",
    "            277.9, 277.7, 277.3, 276.8, 276.3, 275.8, 275.4, 275. , 274.7,\n",
    "            274.4, 274.1, 273.9, 273.8, 273.7, 273.5, 273.4, 273.3, 273.3,\n",
    "            273.5, 273.7, 274.1, 274.6, 275.1, 275.4, 275.7, 276.2, 276.7,\n",
    "            276.9, 276.8, 276.1, 275.1, 274.2, 273.4, 272.5, 272. , 272. ,\n",
    "            272.4]\n",
    "})\n",
    "\n",
    "# tracks = pd.read_csv('outputs/global/helene_tracks_rank_000.csv', sep=',')\n",
    "track_list, _ = extract_tracks_from_csv('outputs/global/helene_tracks_rank_000.csv',\n",
    "                                ic=start_times[0],\n",
    "                                tc_centres=helene_ibtracs_coords,\n",
    "                                max_dist=2.5,\n",
    "                                min_len=4,\n",
    "                                max_stp=nsteps)\n",
    "\n",
    "print(f'found {len(track_list)} tracks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, let's focus on the gulf of mexico and plot the tracks of Hurricane Helene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = 'u10m'\n",
    "ensemble_member = 1\n",
    "\n",
    "max_frames = 17 # maximum number of frames to plot\n",
    "scale = 1\n",
    "\n",
    "lat_min, lat_max = 10, 40\n",
    "lon_min, lon_max = 250, 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "# import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "# from matplotlib.colors import TwoSlopeNorm\n",
    "import matplotlib.animation as animation\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "\n",
    "# import xarray as xr\n",
    "\n",
    "dx = scale*.25\n",
    "\n",
    "countries = cfeature.NaturalEarthFeature(\n",
    "    category=\"cultural\",\n",
    "    name=\"admin_0_countries\",\n",
    "    scale=\"110m\",\n",
    "    facecolor=\"none\",\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "\n",
    "reg_ds = ds.sel(lat=list(np.arange(lat_min, lat_max, dx)),\n",
    "                lon=list(np.arange(lon_min, lon_max, dx)))\n",
    "\n",
    "time_str = 'lead time:'\n",
    "projection=ccrs.PlateCarree()\n",
    "var_ds = reg_ds[variable] # np.sqrt(np.square(reg_ds.u10m) + np.square(reg_ds.v10m))\n",
    "\n",
    "min_val = float(np.min(var_ds[ensemble_member,0,:,:,:]))\n",
    "max_val = float(np.max(var_ds[ensemble_member,0,:,:,:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.colors as colors\n",
    "\n",
    "# define plots\n",
    "def make_figure():\n",
    "    fig = plt.figure(figsize=(11,5))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=projection)\n",
    "\n",
    "    ax.add_feature(cfeature.COASTLINE,lw=.5)\n",
    "    ax.add_feature(cfeature.RIVERS,lw=.5)\n",
    "\n",
    "    lon_formatter = LongitudeFormatter(zero_direction_label=False)\n",
    "    lat_formatter = LatitudeFormatter()\n",
    "    ax.xaxis.set_major_formatter(lon_formatter)\n",
    "    ax.yaxis.set_major_formatter(lat_formatter)\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "def make_frame(frame):\n",
    "    print(f'\\rprocessing frame {frame+1} of {min(max_frames, var_ds.shape[2])}', end='')\n",
    "    plot_ds = var_ds[ensemble_member, 0, max(frame,0), :, :]\n",
    "    pc = ax.pcolormesh(reg_ds.lon, reg_ds.lat, plot_ds, transform=projection,\n",
    "                       cmap='plasma',\n",
    "                       vmin=min_val, vmax=max_val\n",
    "                       )\n",
    "\n",
    "    if frame==-1:\n",
    "        cbar = fig.colorbar(pc, extend='both', shrink=0.8, ax=ax)\n",
    "    else:\n",
    "        track = track_list[ensemble_member]\n",
    "        max_len = min(frame, len(track['lon']))\n",
    "        ax.plot(track['lon'][:max_len]-360, track['lat'][:max_len],\n",
    "                color='white', linewidth=2, alpha=1)\n",
    "\n",
    "    header = time_str + \" \" + f'{frame*6}:00:00'\n",
    "    ax.set_title(header, fontsize=14)\n",
    "\n",
    "    return pc\n",
    "\n",
    "def animate(frame):\n",
    "    return make_frame(frame)\n",
    "\n",
    "def first_frame():\n",
    "    return make_frame(-1)\n",
    "\n",
    "# make animation\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "fig, ax = make_figure()\n",
    "ani = animation.FuncAnimation(fig,\n",
    "                              animate,\n",
    "                              min(max_frames, var_ds.shape[2]),\n",
    "                              init_func=first_frame,\n",
    "                              blit=False,\n",
    "                              repeat=False,\n",
    "                              interval=.1)\n",
    "plt.close('all')\n",
    "ani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and finally, the full spaghetti plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "\n",
    "# fig_size = (lon_max-lon_min,\n",
    "#             lat_max-lat_min)\n",
    "\n",
    "# Set the style to dark background\n",
    "# plt.style.use('dark_background')\n",
    "\n",
    "# Create figure and axis\n",
    "# fig, ax = plt.subplots(figsize=(11, 5),  projection=ccrs.PlateCarree())\n",
    "fig = plt.figure(figsize=(11,5))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=projection)\n",
    "\n",
    "ax.add_feature(cfeature.COASTLINE,lw=.5)\n",
    "ax.add_feature(cfeature.RIVERS,lw=.5)\n",
    "ax.add_feature(cfeature.OCEAN)\n",
    "ax.add_feature(cfeature.LAND)\n",
    "\n",
    "lon_formatter = LongitudeFormatter(zero_direction_label=False)\n",
    "lat_formatter = LatitudeFormatter()\n",
    "ax.xaxis.set_major_formatter(lon_formatter)\n",
    "ax.yaxis.set_major_formatter(lat_formatter)\n",
    "\n",
    "# Plot the line in white\n",
    "for track in track_list:\n",
    "    ax.plot(track['lon']-360, track['lat'],\n",
    "            color='crimson', linewidth=2, alpha=.4)\n",
    "\n",
    "ax.set_extent([lon_min, lon_max, lat_min, lat_max])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
