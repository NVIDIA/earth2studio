{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HENS\n",
    "\n",
    "First, some background info on HENS and that there's more to explore\n",
    "in the folder..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import initialize, compose\n",
    "from omegaconf import DictConfig\n",
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), '11_hens'))\n",
    "load_dotenv()\n",
    "\n",
    "# Import the module\n",
    "from hens import main\n",
    "\n",
    "def load_config(config_name: str = \"config\") -> DictConfig:\n",
    "    with initialize(version_base=None, config_path=\"./11_hens/conf/\"):\n",
    "        cfg = compose(config_name=config_name)\n",
    "        return cfg\n",
    "\n",
    "cfg = load_config(\"helene_nb.yaml\")  # Loads helene.yaml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- why is batch generation progress not shown? To be fixed (cursor knows how, but it isn't clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-15 14:39:34.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutilities\u001b[0m:\u001b[36mpair_packages_ics\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mrank 0: predicting from following models/initial times: [('/media/mkoch/9ee63bf8-5a14-4872-86f2-7f16b120269b/hens_data/hens_checkpoints/sfno_linear_74chq_sc2_layers8_edim620_wstgl2-epoch70_seed102', numpy.datetime64('2024-09-24T12:00:00.000000000'), 0, [0, 1])]\u001b[0m\n",
      "pkg='/media/mkoch/9ee63bf8-5a14-4872-86f2-7f16b120269b/hens_data/hens_checkpoints/sfno_linear_74chq_sc2_layers8_edim620_wstgl2-epoch70_seed102' ic=numpy.datetime64('2024-09-24T12:00:00.000000000') ens_idx=0 batch_ids_produce=[0, 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from ensemble_utilities import EnsembleBase\n",
    "from physicsnemo.distributed import DistributedManager\n",
    "from reproduce_utilities import create_base_seed_string\n",
    "\n",
    "from utilities import (\n",
    "    initialise,\n",
    "    initialise_output,\n",
    "    store_tracks,\n",
    "    update_model_dict,\n",
    "    write_to_disk,\n",
    ")\n",
    "\n",
    "DistributedManager.initialize()\n",
    "\n",
    "(\n",
    "    ensemble_configs,\n",
    "    model_dict,\n",
    "    dx_model_dict,\n",
    "    cyclone_tracking,\n",
    "    data,\n",
    "    output_coords_dict,\n",
    "    base_random_seed,\n",
    "    all_tracks_dict,\n",
    "    writer_executor,\n",
    "    writer_threads\n",
    ") = initialise(cfg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ensemble configs include XYZ and represent blah. Let's have a look at the content and explore how many cases we will run, depending on number of ensemble members, batch size, number of checkpoints and initial conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ii=0 pkg='/media/mkoch/9ee63bf8-5a14-4872-86f2-7f16b120269b/hens_data/hens_checkpoints/sfno_linear_74chq_sc2_layers8_edim620_wstgl2-epoch70_seed102' ic=numpy.datetime64('2024-09-24T12:00:00.000000000') ens_idx=0 batch_ids_produce=[0, 1]\n"
     ]
    }
   ],
   "source": [
    "for ii, (pkg, ic, ens_idx, batch_ids_produce) in enumerate(ensemble_configs):\n",
    "    print(f'{ii=} {pkg=} {ic=} {ens_idx=} {batch_ids_produce=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model dict includes model and weights. Let's have a look at its contents. At each loop, it will be updated according to pkg in provided in the ensemble config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model class is:\n",
      "<class 'earth2studio.models.px.sfno.SFNO'> \n",
      "\n",
      "The model package (weights), which is currently loaded:\n",
      "/media/mkoch/9ee63bf8-5a14-4872-86f2-7f16b120269b/hens_data/hens_checkpoints/sfno_linear_74chq_sc2_layers8_edim620_wstgl2-epoch70_seed102 \n",
      "\n",
      "The fully initialised model is provided in:\n",
      "<bound method Module.parameters of SFNO(\n",
      "  (model): ModelWrapper(\n",
      "    (model): SingleStepWrapper(\n",
      "      (preprocessor): Preprocessor2D()\n",
      "      (model): SphericalFourierNeuralOperatorNet(\n",
      "        (trans_down): RealSHT(\n",
      "          nlat=721, nlon=1440,\n",
      "           lmax=360, mmax=361,\n",
      "           grid=equiangular, csphase=True\n",
      "        )\n",
      "        (itrans_up): InverseRealSHT(\n",
      "          nlat=721, nlon=1440,\n",
      "           lmax=360, mmax=361,\n",
      "           grid=equiangular, csphase=True\n",
      "        )\n",
      "        (trans): RealSHT(\n",
      "          nlat=360, nlon=720,\n",
      "           lmax=360, mmax=361,\n",
      "           grid=legendre-gauss, csphase=True\n",
      "        )\n",
      "        (itrans): InverseRealSHT(\n",
      "          nlat=360, nlon=720,\n",
      "           lmax=360, mmax=361,\n",
      "           grid=legendre-gauss, csphase=True\n",
      "        )\n",
      "        (encoder): EncoderDecoder(\n",
      "          (fwd): Sequential(\n",
      "            (0): Conv2d(110, 620, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Conv2d(620, 620, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (pos_drop): Dropout(p=0.1, inplace=False)\n",
      "        (blocks): ModuleList(\n",
      "          (0): FourierNeuralOperatorBlock(\n",
      "            (norm0): InstanceNorm2d(620, eps=1e-06, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (filter): SpectralFilterLayer(\n",
      "              (filter): SpectralConv(\n",
      "                (forward_transform): RealSHT(\n",
      "                  nlat=721, nlon=1440,\n",
      "                   lmax=360, mmax=361,\n",
      "                   grid=equiangular, csphase=True\n",
      "                )\n",
      "                (inverse_transform): InverseRealSHT(\n",
      "                  nlat=360, nlon=720,\n",
      "                   lmax=360, mmax=361,\n",
      "                   grid=legendre-gauss, csphase=True\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (act_layer0): GELU(approximate='none')\n",
      "            (norm1): InstanceNorm2d(620, eps=1e-06, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (outer_skip): Conv2d(620, 620, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (mlp): MLP(\n",
      "              (fwd): Sequential(\n",
      "                (0): Conv2d(620, 1240, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): GELU(approximate='none')\n",
      "                (2): Identity()\n",
      "                (3): Conv2d(1240, 620, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (4): Identity()\n",
      "              )\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1-6): 6 x FourierNeuralOperatorBlock(\n",
      "            (norm0): InstanceNorm2d(620, eps=1e-06, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (filter): SpectralFilterLayer(\n",
      "              (filter): SpectralConv(\n",
      "                (forward_transform): RealSHT(\n",
      "                  nlat=360, nlon=720,\n",
      "                   lmax=360, mmax=361,\n",
      "                   grid=legendre-gauss, csphase=True\n",
      "                )\n",
      "                (inverse_transform): InverseRealSHT(\n",
      "                  nlat=360, nlon=720,\n",
      "                   lmax=360, mmax=361,\n",
      "                   grid=legendre-gauss, csphase=True\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (act_layer0): GELU(approximate='none')\n",
      "            (norm1): InstanceNorm2d(620, eps=1e-06, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (outer_skip): Conv2d(620, 620, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (mlp): MLP(\n",
      "              (fwd): Sequential(\n",
      "                (0): Conv2d(620, 1240, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): GELU(approximate='none')\n",
      "                (2): Identity()\n",
      "                (3): Conv2d(1240, 620, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (4): Identity()\n",
      "              )\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (7): FourierNeuralOperatorBlock(\n",
      "            (norm0): InstanceNorm2d(620, eps=1e-06, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (filter): SpectralFilterLayer(\n",
      "              (filter): SpectralConv(\n",
      "                (forward_transform): RealSHT(\n",
      "                  nlat=360, nlon=720,\n",
      "                   lmax=360, mmax=361,\n",
      "                   grid=legendre-gauss, csphase=True\n",
      "                )\n",
      "                (inverse_transform): InverseRealSHT(\n",
      "                  nlat=721, nlon=1440,\n",
      "                   lmax=360, mmax=361,\n",
      "                   grid=equiangular, csphase=True\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (act_layer0): GELU(approximate='none')\n",
      "            (norm1): InstanceNorm2d(620, eps=1e-06, momentum=0.1, affine=True, track_running_stats=False)\n",
      "            (outer_skip): Conv2d(620, 620, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (mlp): MLP(\n",
      "              (fwd): Sequential(\n",
      "                (0): Conv2d(620, 1240, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): GELU(approximate='none')\n",
      "                (2): Identity()\n",
      "                (3): Conv2d(1240, 620, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (4): Identity()\n",
      "              )\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "        (decoder): EncoderDecoder(\n",
      "          (fwd): Sequential(\n",
      "            (0): Conv2d(620, 620, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Conv2d(620, 74, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (residual_transform): Conv2d(110, 74, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('The model class is:')\n",
    "print(model_dict['class'], '\\n')\n",
    "\n",
    "print('The model package (weights), which is currently loaded:')\n",
    "print(model_dict['package'], '\\n')\n",
    "\n",
    "print('The fully initialised model is provided in:')\n",
    "print(model_dict['model'].parameters, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hens_perturbation import HENSPerturbation\n",
    "\n",
    "from numpy import ndarray, datetime64\n",
    "\n",
    "from earth2studio.data import DataSource\n",
    "from earth2studio.models.px import PrognosticModel\n",
    "from earth2studio.perturbation import Perturbation\n",
    "\n",
    "def initialise_perturbation(\n",
    "    model: PrognosticModel,\n",
    "    data: DataSource,\n",
    "    start_time: ndarray[datetime64],\n",
    "    cfg: DictConfig,\n",
    ") -> Perturbation:\n",
    "    perturbation = HENSPerturbation(\n",
    "        model=model,\n",
    "        data=data,\n",
    "        start_time=start_time,\n",
    "        skill_path=cfg.perturbation.skill_path,\n",
    "        noise_amplification=cfg.perturbation.noise_amplification,\n",
    "        perturbed_var=cfg.perturbation.perturbed_var,\n",
    "        integration_steps=cfg.perturbation.integration_steps\n",
    "    )\n",
    "\n",
    "    return perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching GFS for 2024-09-23 18:00:00: 100%|██████████| 74/74 [00:01<00:00, 44.61it/s]\n",
      "Fetching GFS for 2024-09-24 00:00:00: 100%|██████████| 74/74 [00:01<00:00, 55.15it/s]\n",
      "Fetching GFS for 2024-09-24 06:00:00: 100%|██████████| 74/74 [00:01<00:00, 55.40it/s]\n",
      "Fetching GFS for 2024-09-24 12:00:00: 100%|██████████| 74/74 [00:01<00:00, 54.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-15 14:39:40.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mensemble_utilities\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1mSetting up HENS.\u001b[0m\n",
      "\u001b[32m2025-04-15 14:39:40.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mensemble_utilities\u001b[0m:\u001b[36mmove_models_to_device\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1mInference device: cuda\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching GFS for 2024-09-24 12:00:00: 100%|██████████| 74/74 [00:01<00:00, 55.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-15 14:39:43.673\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mensemble_utilities\u001b[0m:\u001b[36mfetch_ics\u001b[0m:\u001b[36m192\u001b[0m - \u001b[32m\u001b[1mFetched data from GFS\u001b[0m\n",
      "\u001b[32m2025-04-15 14:39:43.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mensemble_utilities\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m324\u001b[0m - \u001b[1mStarting 4 Member Ensemble inference with 2 number of batches.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Ensemble Batches: 100%|██████████| 2/2 [01:01<00:00, 30.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-15 14:40:44.848\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mensemble_utilities\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m381\u001b[0m - \u001b[32m\u001b[1mInference complete\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# run forecasts\n",
    "for pkg, ic, ens_idx, batch_ids_produce in ensemble_configs:\n",
    "    # create seed base string required for reproducibility of individual batches\n",
    "    base_seed_string = create_base_seed_string(pkg, ic, base_random_seed)\n",
    "\n",
    "    # load new weights if necessary\n",
    "    model_dict = update_model_dict(model_dict, pkg)\n",
    "\n",
    "    io_dict = initialise_output(cfg, ic, model_dict, output_coords_dict)\n",
    "\n",
    "    perturbation = initialise_perturbation(\n",
    "        model=model_dict[\"model\"], data=data, start_time=ic, cfg=cfg\n",
    "    )\n",
    "\n",
    "    run_hens = EnsembleBase(\n",
    "        time=[ic],\n",
    "        nsteps=cfg.nsteps,\n",
    "        nensemble=cfg.nensemble,\n",
    "        prognostic=model_dict[\"model\"],\n",
    "        data=data,\n",
    "        io_dict=io_dict,\n",
    "        perturbation=perturbation,\n",
    "        output_coords_dict=output_coords_dict,\n",
    "        dx_model_dict=dx_model_dict,\n",
    "        cyclone_tracking=cyclone_tracking,\n",
    "        batch_size=cfg.batch_size,\n",
    "        ensemble_idx_base=ens_idx,\n",
    "        batch_ids_produce=batch_ids_produce,\n",
    "        base_seed_string=base_seed_string,\n",
    "    )\n",
    "    df_tracks_dict, io_dict = run_hens()\n",
    "    for k, v in df_tracks_dict.items():\n",
    "        v[\"ic\"] = pd.to_datetime(ic)\n",
    "        all_tracks_dict[k].append(v)\n",
    "\n",
    "    # if in-memory flavour of io backend was chosen, write content to disk now\n",
    "    if io_dict:\n",
    "        writer_threads, writer_executor = write_to_disk(\n",
    "            cfg,\n",
    "            ic,\n",
    "            model_dict,\n",
    "            io_dict,\n",
    "            writer_threads,\n",
    "            writer_executor,\n",
    "            ens_idx,\n",
    "        )\n",
    "\n",
    "# Output summaries of cyclone tracks if required\n",
    "if \"cyclone_tracking\" in cfg:\n",
    "    for area_name, all_tracks in all_tracks_dict.items():\n",
    "        store_tracks(area_name, all_tracks, cfg)\n",
    "\n",
    "if writer_executor is not None:\n",
    "    for thread in list(writer_threads):\n",
    "        thread.result()\n",
    "        writer_threads.remove(thread)\n",
    "    writer_executor.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
