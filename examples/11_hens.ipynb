{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HENS\n",
    "\n",
    "First, some background info on HENS and that there's more to explore\n",
    "in the folder...\n",
    "\n",
    "This notebook shall give you an overview of key concepts in the pipeline.\n",
    "\n",
    "In `11_hens/` you will find an extensive doc in the form of a README, inlcuding\n",
    "examples to run HENS with different configurations at scale.\n",
    "\n",
    "Quite a few configs to be tweaked, so we will set the most important ones here\n",
    "and then turn them into a config opbject afterwards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'helene'\n",
    "\n",
    "start_times = [\"2024-09-24 12:00:00\"]\n",
    "nsteps = 16\n",
    "nensemble = 4\n",
    "batch_size = 2\n",
    "\n",
    "model_packages = '/media/mkoch/9ee63bf8-5a14-4872-86f2-7f16b120269b/hens_data/hens_checkpoints'\n",
    "max_num_checkpoints = 2\n",
    "\n",
    "output_vars = [\"t2m\", 'u10m', 'v10m', 'u850', 'v850', 'msl', 'z500']\n",
    "out_dir = './outputs'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next, let's do some imports and fully configure the inference. for more detailed\n",
    "info about the configurations, see the README in the 11_hens folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import DictConfig\n",
    "from physicsnemo.distributed import DistributedManager\n",
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), '11_hens'))\n",
    "load_dotenv()\n",
    "DistributedManager.initialize()\n",
    "\n",
    "# Create the configuration dictionary\n",
    "cfg = DictConfig({\n",
    "    'project': project,\n",
    "    'random_seed': 377778,\n",
    "    'start_times': start_times,\n",
    "    'nsteps': nsteps,          # number of forecasting steps\n",
    "    'nensemble': nensemble,       # ensemble size per checkpoint\n",
    "    'batch_size': batch_size,      # inference batch size\n",
    "\n",
    "    'forecast_model': {\n",
    "        'architecture': 'earth2studio.models.px.SFNO',   # forecast model class\n",
    "        'package': model_packages,\n",
    "        'max_num_checkpoints': max_num_checkpoints  # max number of checkpoints which will be used\n",
    "    },\n",
    "\n",
    "    'data_source': {\n",
    "        '_target_': 'earth2studio.data.GFS'  # data source class\n",
    "    },\n",
    "\n",
    "    'cyclone_tracking': {\n",
    "        'out_dir': out_dir\n",
    "    },\n",
    "\n",
    "    'file_output': {\n",
    "        'path': out_dir,       # directory to which outfiles are written\n",
    "        'output_vars': output_vars,\n",
    "        'thread_io': False,      # write out in separate thread\n",
    "        'format': {              # io backend class\n",
    "            '_target_': 'earth2studio.io.NetCDF4Backend',\n",
    "            '_partial_': True,\n",
    "            'backend_kwargs': {\n",
    "                'mode': 'w',\n",
    "                'diskless': False,\n",
    "                'persist': False,\n",
    "                'chunks': {\n",
    "                    'ensemble': 1,\n",
    "                    'time': 1,\n",
    "                    'lead_time': 1\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- why is batch generation progress not shown? To be fixed (cursor knows how, but it isn't clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from ensemble_utilities import EnsembleBase\n",
    "from reproduce_utilities import create_base_seed_string\n",
    "\n",
    "from utilities import (\n",
    "    initialise,\n",
    "    initialise_output,\n",
    "    store_tracks,\n",
    "    update_model_dict,\n",
    "    write_to_disk,\n",
    ")\n",
    "\n",
    "(\n",
    "    ensemble_configs,\n",
    "    model_dict,\n",
    "    dx_model_dict,\n",
    "    cyclone_tracking,\n",
    "    data,\n",
    "    output_coords_dict,\n",
    "    base_random_seed,\n",
    "    all_tracks_dict,\n",
    "    _, _\n",
    ") = initialise(cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ensemble configs include XYZ and represent blah. Let's have a look at the content and explore how many cases we will run, depending on number of ensemble members, batch size, number of checkpoints and initial conditions.\n",
    "\n",
    "The inference is parallelised across enssemble config entries, hence across IC-package pairs. This also menas that you cannot use more GPUs than number of ICs multiplied by number of checkpoints. If more GPUs are available, they remain idle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii, (pkg, ic, ens_idx, batch_ids_produce) in enumerate(ensemble_configs):\n",
    "    print(f'ensemble config {ii+1} of {len(ensemble_configs)}:')\n",
    "    print(f'    package: {pkg}')\n",
    "    print(f'    initial condition: {ic}')\n",
    "    print(f'    ensemble index of first member: {ens_idx}')\n",
    "    print(f'    batch ids to produce: {batch_ids_produce}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model dict includes model and weights. Let's have a look at its contents. At each loop, it will be updated according to pkg in provided in the ensemble config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored\n",
    "\n",
    "print(colored('The model class is:', attrs=['bold']))\n",
    "print(model_dict['class'], '\\n')\n",
    "\n",
    "print(colored('The model package (weights), which is currently loaded:', attrs=['bold']))\n",
    "print(model_dict['package'], '\\n')\n",
    "\n",
    "print(colored('The fully initialised model is provided in:', attrs=['bold']))\n",
    "print(model_dict['model'].parameters, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to set up HENS perturbation.\n",
    "to see how it is aseembled form basic blocks porvided in e2studio, have a look into `11_hens/hens_perturbation.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for perturbation\n",
    "skill_path = \"/media/mkoch/9ee63bf8-5a14-4872-86f2-7f16b120269b/hens_data/hens_checkpoints/d2m_sfno_linear_74chq_sc2_layers8_edim620_wstgl2-epoch70_seed16.nc\"\n",
    "noise_amplification = 0.35\n",
    "perturbed_var = [\"z500\"]\n",
    "integration_steps = 3\n",
    "\n",
    "from hens_perturbation import HENSPerturbation\n",
    "\n",
    "from numpy import ndarray, datetime64\n",
    "\n",
    "from earth2studio.data import DataSource\n",
    "from earth2studio.models.px import PrognosticModel\n",
    "from earth2studio.perturbation import Perturbation\n",
    "\n",
    "def initialise_perturbation(\n",
    "    model: PrognosticModel,\n",
    "    data: DataSource,\n",
    "    start_time: ndarray[datetime64],\n",
    ") -> Perturbation:\n",
    "    perturbation = HENSPerturbation(\n",
    "        model=model,\n",
    "        data=data,\n",
    "        start_time=start_time,\n",
    "        skill_path=skill_path,\n",
    "        noise_amplification=noise_amplification,\n",
    "        perturbed_var=perturbed_var,\n",
    "        integration_steps=integration_steps\n",
    "    )\n",
    "\n",
    "    return perturbation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now bring everyhting together:\n",
    "- loop over ensemble configs\n",
    "- update model dict (if package has changed)\n",
    "- initialise output\n",
    "- initialise perturbation (as ICs might have changed)\n",
    "- run inference, where all ensemble members are produced\n",
    "- write to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over ensemble configs\n",
    "for pkg, ic, ens_idx, batch_ids_produce in ensemble_configs:\n",
    "    # create seed base string required for reproducibility of individual batches\n",
    "    base_seed_string = create_base_seed_string(pkg, ic, base_random_seed)\n",
    "\n",
    "    # load new weights if necessary\n",
    "    model_dict = update_model_dict(model_dict, pkg)\n",
    "\n",
    "    # create new io object\n",
    "    io_dict = initialise_output(cfg, ic, model_dict, output_coords_dict)\n",
    "\n",
    "    # initialise perturbation with updated IC and checkpoint\n",
    "    perturbation = initialise_perturbation(\n",
    "        model=model_dict[\"model\"], data=data, start_time=ic\n",
    "    )\n",
    "\n",
    "    # initialise inference pipeline with updated IC and checkpoint\n",
    "    run_hens = EnsembleBase(\n",
    "        time=[ic],\n",
    "        nsteps=cfg.nsteps,\n",
    "        nensemble=cfg.nensemble,\n",
    "        prognostic=model_dict[\"model\"],\n",
    "        data=data,\n",
    "        io_dict=io_dict,\n",
    "        perturbation=perturbation,\n",
    "        output_coords_dict=output_coords_dict,\n",
    "        dx_model_dict=dx_model_dict,\n",
    "        cyclone_tracking=cyclone_tracking,\n",
    "        batch_size=cfg.batch_size,\n",
    "        ensemble_idx_base=ens_idx,\n",
    "        batch_ids_produce=batch_ids_produce,\n",
    "        base_seed_string=base_seed_string,\n",
    "    )\n",
    "\n",
    "    # run inference\n",
    "    df_tracks_dict, io_dict = run_hens()\n",
    "\n",
    "    # store tracks\n",
    "    for k, v in df_tracks_dict.items():\n",
    "        v[\"ic\"] = pd.to_datetime(ic)\n",
    "        all_tracks_dict[k].append(v)\n",
    "\n",
    "    # if in-memory flavour of io backend was chosen, write content to disk now\n",
    "    if io_dict:\n",
    "        _, _ = write_to_disk(\n",
    "            cfg,\n",
    "            ic,\n",
    "            model_dict,\n",
    "            io_dict,\n",
    "            None,\n",
    "            None,\n",
    "        )\n",
    "\n",
    "# write cyclone tracks to disk\n",
    "if \"cyclone_tracking\" in cfg:\n",
    "    for area_name, all_tracks in all_tracks_dict.items():\n",
    "        store_tracks(area_name, all_tracks, cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, there should be a folder called \"output\" with all the forecasts.\n",
    "Also the tracks should be in there.\n",
    "\n",
    "plot tracks and fields.\n",
    "\n",
    "as we can see there are 4 members, one IC (time), 4 lead time in the field output\n",
    "\n",
    "track headers mean xyz...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from plotting.fork_n_spoon import extract_tracks_from_csv\n",
    "\n",
    "ds = xr.load_dataset('outputs/global/helene_2024-09-24T12_pkg_seed102.nc')\n",
    "display(ds)\n",
    "\n",
    "tracks = pd.read_csv('outputs/global/helene_tracks_rank_000.csv', sep=',')\n",
    "print('tracks columns:')\n",
    "print(list(tracks.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot global fields through:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['t2m'].isel(ensemble=0, lead_time=0, time=0).plot(figsize=(16, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's extract helene tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting.fork_n_spoon import ibtracs_helene\n",
    "\n",
    "# tracks = pd.read_csv('outputs/global/helene_tracks_rank_000.csv', sep=',')\n",
    "track_list, _ = extract_tracks_from_csv('outputs/global/helene_tracks_rank_000.csv',\n",
    "                                ic=start_times[0],\n",
    "                                tc_centres=ibtracs_helene(),\n",
    "                                max_dist=2.5,\n",
    "                                min_len=4,\n",
    "                                max_stp=nsteps)\n",
    "\n",
    "print(f'found {len(track_list)} tracks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, let's focus on the gulf of mexico and plot the tracks of Hurricane Helene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = 'u10m'\n",
    "ensemble_member = 1\n",
    "\n",
    "max_frames = 17 # maximum number of frames to plot\n",
    "scale = 1\n",
    "\n",
    "lat_min, lat_max = 10, 40\n",
    "lon_min, lon_max = 250, 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.animation as animation\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "\n",
    "from plotting.fork_n_spoon import make_figure, make_frame\n",
    "\n",
    "dx = scale*.25\n",
    "\n",
    "countries = cfeature.NaturalEarthFeature(\n",
    "    category=\"cultural\",\n",
    "    name=\"admin_0_countries\",\n",
    "    scale=\"110m\",\n",
    "    facecolor=\"none\",\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "\n",
    "# extract region of interest\n",
    "reg_ds = ds.sel(lat=list(np.arange(lat_min, lat_max, dx)),\n",
    "                lon=list(np.arange(lon_min, lon_max, dx)))\n",
    "\n",
    "time_str = 'lead time:'\n",
    "projection=ccrs.PlateCarree()\n",
    "var_ds = reg_ds[variable] # np.sqrt(np.square(reg_ds.u10m) + np.square(reg_ds.v10m))\n",
    "\n",
    "min_val = float(np.min(var_ds[ensemble_member,0,:,:,:]))\n",
    "max_val = float(np.max(var_ds[ensemble_member,0,:,:,:]))\n",
    "\n",
    "# make animation\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "fig, ax = make_figure(projection=ccrs.PlateCarree())\n",
    "\n",
    "_make_frame = make_frame(fig, ax, var_ds, ensemble_member, track_list, max_frames, min_val, max_val, projection, reg_ds, time_str)\n",
    "\n",
    "def animate(frame):\n",
    "    return _make_frame(frame)\n",
    "\n",
    "def first_frame():\n",
    "    return _make_frame(-1)\n",
    "\n",
    "ani = animation.FuncAnimation(fig,\n",
    "                              animate,\n",
    "                              min(max_frames, var_ds.shape[2]),\n",
    "                              init_func=first_frame,\n",
    "                              blit=False,\n",
    "                              repeat=False,\n",
    "                              interval=.1)\n",
    "plt.close('all')\n",
    "display(ani)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and finally, the full spaghetti plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "\n",
    "fig = plt.figure(figsize=(11,5))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=projection)\n",
    "\n",
    "ax.add_feature(cfeature.COASTLINE,lw=.5)\n",
    "ax.add_feature(cfeature.RIVERS,lw=.5)\n",
    "ax.add_feature(cfeature.OCEAN)\n",
    "ax.add_feature(cfeature.LAND)\n",
    "\n",
    "lon_formatter = LongitudeFormatter(zero_direction_label=False)\n",
    "lat_formatter = LatitudeFormatter()\n",
    "ax.xaxis.set_major_formatter(lon_formatter)\n",
    "ax.yaxis.set_major_formatter(lat_formatter)\n",
    "\n",
    "# Plot the line in white\n",
    "for track in track_list:\n",
    "    ax.plot(track['lon']-360, track['lat'],\n",
    "            color='crimson', linewidth=2, alpha=.4)\n",
    "\n",
    "ax.set_extent([lon_min, lon_max, lat_min, lat_max])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
