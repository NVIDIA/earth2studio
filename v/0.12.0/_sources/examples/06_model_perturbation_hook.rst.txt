
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "examples/06_model_perturbation_hook.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_examples_06_model_perturbation_hook.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_06_model_perturbation_hook.py:


Model Hook Injection: Perturbation
==================================

Adding model noise by using custom hooks.

This example will demonstrate how to run an ensemble inference workflow to generate a
perturbed ensemble forecast. This perturbation is done by injecting code into the model
front and rear hooks.
These hooks are applied to the tensor data before/after the model forward call.

This example also illustrates how you can subselect data for IO. In this example we
will only output two variables:
total column water vapor (tcwv) and 500 hPa geopotential (z500).
To run this, make sure that the model selected predicts these variables are change
appropriately.

In this example you will learn:

- How to instantiate a built in prognostic model
- Creating a data source and IO object
- Changing the model forward/rear hooks
- Choose a subselection of coordinates to save to an IO object.
- Post-processing results

.. GENERATED FROM PYTHON SOURCE LINES 43-50

.. code-block:: Python

    # /// script
    # dependencies = [
    #   "earth2studio[dlwp] @ git+https://github.com/NVIDIA/earth2studio.git@0.12.0",
    #   "cartopy",
    # ]
    # ///








.. GENERATED FROM PYTHON SOURCE LINES 51-70

Creating an Ensemble Workflow
-----------------------------

To start let's begin with creating an ensemble workflow to use. We encourage
users to explore and experiment with their own custom workflows that borrow ideas from
built in workflows inside :py:obj:`earth2studio.run` or the examples.

Creating our own generalizable ensemble workflow is easy when we rely on the component
interfaces defined in Earth2Studio (use dependency injection). Here we create a run
method that accepts the following:

- time: Input list of datetimes / strings to run inference for
- nsteps: Number of forecast steps to predict
- nensemble: Number of ensembles to run for
- prognostic: Our initialized prognostic model
- data: Initialized data source to fetch initial conditions from
- io: io store that data is written to.
- output_coords: CoordSystem of output coordinates that should be saved. Should be
  a proper subset of model output coordinates.

.. GENERATED FROM PYTHON SOURCE LINES 72-86

Set Up
------
With the ensemble workflow defined, we now need to create the individual components.

We need the following:

- Prognostic Model: Use the built in DLWP model :py:class:`earth2studio.models.px.DLWP`.
- Datasource: Pull data from the GFS data api :py:class:`earth2studio.data.GFS`.
- IO Backend: Save the outputs into a Zarr store :py:class:`earth2studio.io.ZarrBackend`.

We will first run the ensemble workflow using an unmodified function, that is a model that has the
default (identity) forward and rear hooks. Then we will define new hooks for the model and rerun the
inference request.
%%

.. GENERATED FROM PYTHON SOURCE LINES 86-113

.. code-block:: Python

    import os

    os.makedirs("outputs", exist_ok=True)
    from dotenv import load_dotenv

    load_dotenv()  # TODO: make common example prep function

    import numpy as np

    from earth2studio.data import GFS
    from earth2studio.io import ZarrBackend
    from earth2studio.models.px import DLWP
    from earth2studio.perturbation import Gaussian
    from earth2studio.run import ensemble

    # Load the default model package which downloads the check point from NGC
    package = DLWP.load_default_package()
    model = DLWP.load_model(package)

    # Create the data source
    data = GFS()

    # Create the IO handler, store in memory
    chunks = {"ensemble": 1, "time": 1, "lead_time": 1}
    io_unperturbed = ZarrBackend(file_name="outputs/05_ensemble.zarr", chunks=chunks)









.. GENERATED FROM PYTHON SOURCE LINES 114-122

Execute the Workflow
--------------------
First, we will run the ensemble workflow but with a :py:meth:`earth2studio.perturbation.Gaussian`
perturbation as the control.

The workflow will return the provided IO object back to the user, which can be used to
then post process. Some have additional APIs that can be handy for post-processing or
saving to file. Check the API docs for more information.

.. GENERATED FROM PYTHON SOURCE LINES 124-147

.. code-block:: Python

    nsteps = 4 * 12
    nensemble = 16
    batch_size = 4
    forecast_date = "2024-01-30"
    output_coords = {
        "lat": np.arange(25.0, 60.0, 0.25),
        "lon": np.arange(230.0, 300.0, 0.25),
        "variable": np.array(["tcwv", "z500"]),
    }

    # First run with no model perturbation
    io_unperturbed = ensemble(
        [forecast_date],
        nsteps,
        nensemble,
        model,
        data,
        io_unperturbed,
        Gaussian(noise_amplitude=0.01),
        output_coords=output_coords,
        batch_size=batch_size,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    2026-01-27 22:48:42.496 | INFO     | earth2studio.run:ensemble:328 - Running ensemble inference!
    2026-01-27 22:48:42.496 | INFO     | earth2studio.run:ensemble:336 - Inference device: cuda
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]                                                            2026-01-27 22:48:42.913 | DEBUG    | earth2studio.data.gfs:fetch_array:382 - Fetching GFS grib file: noaa-gfs-bdp-pds/gfs.20240129/18/atmos/gfs.t18z.pgrb2.0p25.f000 333455139-848796
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]                                                            2026-01-27 22:48:42.916 | DEBUG    | earth2studio.data.gfs:fetch_array:382 - Fetching GFS grib file: noaa-gfs-bdp-pds/gfs.20240129/18/atmos/gfs.t18z.pgrb2.0p25.f000 402393843-1000454
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]                                                            2026-01-27 22:48:42.929 | DEBUG    | earth2studio.data.gfs:fetch_array:382 - Fetching GFS grib file: noaa-gfs-bdp-pds/gfs.20240129/18/atmos/gfs.t18z.pgrb2.0p25.f000 298404811-863710
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]                                                            2026-01-27 22:48:42.930 | DEBUG    | earth2studio.data.gfs:fetch_array:382 - Fetching GFS grib file: noaa-gfs-bdp-pds/gfs.20240129/18/atmos/gfs.t18z.pgrb2.0p25.f000 424587978-1175298
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]                                                            2026-01-27 22:48:42.932 | DEBUG    | earth2studio.data.gfs:fetch_array:382 - Fetching GFS grib file: noaa-gfs-bdp-pds/gfs.20240129/18/atmos/gfs.t18z.pgrb2.0p25.f000 255947617-818002
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]                                                            2026-01-27 22:48:42.934 | DEBUG    | earth2studio.data.gfs:fetch_array:382 - Fetching GFS grib file: noaa-gfs-bdp-pds/gfs.20240129/18/atmos/gfs.t18z.pgrb2.0p25.f000 412982869-882301
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]                                                            2026-01-27 22:48:42.935 | DEBUG    | earth2studio.data.gfs:fetch_array:382 - Fetching GFS grib file: noaa-gfs-bdp-pds/gfs.20240129/18/atmos/gfs.t18z.pgrb2.0p25.f000 213960931-731790
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]    Fetching GFS data:  14%|█▍        | 1/7 [00:00<00:03,  1.69it/s]    Fetching GFS data:  71%|███████▏  | 5/7 [00:01<00:00,  4.23it/s]    Fetching GFS data:  86%|████████▌ | 6/7 [00:02<00:00,  2.37it/s]    Fetching GFS data: 100%|██████████| 7/7 [00:02<00:00,  2.24it/s]    Fetching GFS data: 100%|██████████| 7/7 [00:02<00:00,  2.46it/s]
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]                                                            2026-01-27 22:48:46.160 | DEBUG    | earth2studio.data.gfs:fetch_array:382 - Fetching GFS grib file: noaa-gfs-bdp-pds/gfs.20240130/00/atmos/gfs.t00z.pgrb2.0p25.f000 419044588-1178697
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]                                                            2026-01-27 22:48:46.163 | DEBUG    | earth2studio.data.gfs:fetch_array:382 - Fetching GFS grib file: noaa-gfs-bdp-pds/gfs.20240130/00/atmos/gfs.t00z.pgrb2.0p25.f000 297270945-860182
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]                                                            2026-01-27 22:48:46.165 | DEBUG    | earth2studio.data.gfs:fetch_array:382 - Fetching GFS grib file: noaa-gfs-bdp-pds/gfs.20240130/00/atmos/gfs.t00z.pgrb2.0p25.f000 407596993-877008
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]                                                            2026-01-27 22:48:46.166 | DEBUG    | earth2studio.data.gfs:fetch_array:382 - Fetching GFS grib file: noaa-gfs-bdp-pds/gfs.20240130/00/atmos/gfs.t00z.pgrb2.0p25.f000 256366833-813140
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]                                                            2026-01-27 22:48:46.168 | DEBUG    | earth2studio.data.gfs:fetch_array:382 - Fetching GFS grib file: noaa-gfs-bdp-pds/gfs.20240130/00/atmos/gfs.t00z.pgrb2.0p25.f000 330480536-845677
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]                                                            2026-01-27 22:48:46.170 | DEBUG    | earth2studio.data.gfs:fetch_array:382 - Fetching GFS grib file: noaa-gfs-bdp-pds/gfs.20240130/00/atmos/gfs.t00z.pgrb2.0p25.f000 397114008-995975
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]                                                            2026-01-27 22:48:46.172 | DEBUG    | earth2studio.data.gfs:fetch_array:382 - Fetching GFS grib file: noaa-gfs-bdp-pds/gfs.20240130/00/atmos/gfs.t00z.pgrb2.0p25.f000 214406883-731397
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]    Fetching GFS data:  14%|█▍        | 1/7 [00:00<00:03,  1.59it/s]    Fetching GFS data:  86%|████████▌ | 6/7 [00:01<00:00,  4.17it/s]    Fetching GFS data: 100%|██████████| 7/7 [00:02<00:00,  2.13it/s]    Fetching GFS data: 100%|██████████| 7/7 [00:02<00:00,  2.38it/s]
    2026-01-27 22:48:49.141 | SUCCESS  | earth2studio.run:ensemble:358 - Fetched data from GFS
    2026-01-27 22:48:49.187 | INFO     | earth2studio.run:ensemble:386 - Starting 16 Member Ensemble Inference with             4 number of batches.


    Total Ensemble Batches:   0%|          | 0/4 [00:00<?, ?it/s]
    Running batch 0 inference:   0%|          | 0/49 [00:00<?, ?it/s]
    Running batch 0 inference:   4%|▍         | 2/49 [00:00<00:02, 15.87it/s]
    Running batch 0 inference:   8%|▊         | 4/49 [00:00<00:02, 15.65it/s]
    Running batch 0 inference:  12%|█▏        | 6/49 [00:00<00:02, 15.59it/s]
    Running batch 0 inference:  16%|█▋        | 8/49 [00:00<00:02, 15.81it/s]
    Running batch 0 inference:  20%|██        | 10/49 [00:00<00:02, 15.96it/s]
    Running batch 0 inference:  24%|██▍       | 12/49 [00:00<00:02, 16.17it/s]
    Running batch 0 inference:  29%|██▊       | 14/49 [00:00<00:02, 16.25it/s]
    Running batch 0 inference:  33%|███▎      | 16/49 [00:00<00:01, 16.55it/s]
    Running batch 0 inference:  37%|███▋      | 18/49 [00:01<00:01, 16.40it/s]
    Running batch 0 inference:  41%|████      | 20/49 [00:01<00:01, 16.57it/s]
    Running batch 0 inference:  45%|████▍     | 22/49 [00:01<00:01, 16.55it/s]
    Running batch 0 inference:  49%|████▉     | 24/49 [00:01<00:01, 16.51it/s]
    Running batch 0 inference:  53%|█████▎    | 26/49 [00:01<00:01, 16.48it/s]
    Running batch 0 inference:  57%|█████▋    | 28/49 [00:01<00:01, 16.55it/s]
    Running batch 0 inference:  61%|██████    | 30/49 [00:01<00:01, 16.59it/s]
    Running batch 0 inference:  65%|██████▌   | 32/49 [00:01<00:01, 16.57it/s]
    Running batch 0 inference:  69%|██████▉   | 34/49 [00:02<00:00, 16.43it/s]
    Running batch 0 inference:  73%|███████▎  | 36/49 [00:02<00:00, 16.67it/s]
    Running batch 0 inference:  78%|███████▊  | 38/49 [00:02<00:00, 16.86it/s]
    Running batch 0 inference:  82%|████████▏ | 40/49 [00:02<00:00, 16.92it/s]
    Running batch 0 inference:  86%|████████▌ | 42/49 [00:02<00:00, 17.23it/s]
    Running batch 0 inference:  90%|████████▉ | 44/49 [00:02<00:00, 17.39it/s]
    Running batch 0 inference:  94%|█████████▍| 46/49 [00:02<00:00, 17.35it/s]
    Running batch 0 inference:  98%|█████████▊| 48/49 [00:02<00:00, 17.30it/s]
                                                                              

    Total Ensemble Batches:  25%|██▌       | 1/4 [00:02<00:08,  2.93s/it]
    Running batch 4 inference:   0%|          | 0/49 [00:00<?, ?it/s]
    Running batch 4 inference:   4%|▍         | 2/49 [00:00<00:02, 16.48it/s]
    Running batch 4 inference:   8%|▊         | 4/49 [00:00<00:02, 16.94it/s]
    Running batch 4 inference:  12%|█▏        | 6/49 [00:00<00:02, 17.09it/s]
    Running batch 4 inference:  16%|█▋        | 8/49 [00:00<00:02, 17.13it/s]
    Running batch 4 inference:  20%|██        | 10/49 [00:00<00:02, 17.12it/s]
    Running batch 4 inference:  24%|██▍       | 12/49 [00:00<00:02, 17.27it/s]
    Running batch 4 inference:  29%|██▊       | 14/49 [00:00<00:02, 17.35it/s]
    Running batch 4 inference:  33%|███▎      | 16/49 [00:00<00:01, 17.33it/s]
    Running batch 4 inference:  37%|███▋      | 18/49 [00:01<00:01, 17.24it/s]
    Running batch 4 inference:  41%|████      | 20/49 [00:01<00:01, 17.09it/s]
    Running batch 4 inference:  45%|████▍     | 22/49 [00:01<00:01, 16.96it/s]
    Running batch 4 inference:  49%|████▉     | 24/49 [00:01<00:01, 16.87it/s]
    Running batch 4 inference:  53%|█████▎    | 26/49 [00:01<00:01, 16.68it/s]
    Running batch 4 inference:  57%|█████▋    | 28/49 [00:01<00:01, 16.68it/s]
    Running batch 4 inference:  61%|██████    | 30/49 [00:01<00:01, 16.57it/s]
    Running batch 4 inference:  65%|██████▌   | 32/49 [00:01<00:01, 16.52it/s]
    Running batch 4 inference:  69%|██████▉   | 34/49 [00:02<00:00, 16.45it/s]
    Running batch 4 inference:  73%|███████▎  | 36/49 [00:02<00:00, 16.52it/s]
    Running batch 4 inference:  78%|███████▊  | 38/49 [00:02<00:00, 16.79it/s]
    Running batch 4 inference:  82%|████████▏ | 40/49 [00:02<00:00, 16.83it/s]
    Running batch 4 inference:  86%|████████▌ | 42/49 [00:02<00:00, 16.87it/s]
    Running batch 4 inference:  90%|████████▉ | 44/49 [00:02<00:00, 16.85it/s]
    Running batch 4 inference:  94%|█████████▍| 46/49 [00:02<00:00, 17.01it/s]
    Running batch 4 inference:  98%|█████████▊| 48/49 [00:02<00:00, 17.17it/s]
                                                                              

    Total Ensemble Batches:  50%|█████     | 2/4 [00:05<00:05,  2.90s/it]
    Running batch 8 inference:   0%|          | 0/49 [00:00<?, ?it/s]
    Running batch 8 inference:   4%|▍         | 2/49 [00:00<00:02, 17.50it/s]
    Running batch 8 inference:   8%|▊         | 4/49 [00:00<00:02, 17.45it/s]
    Running batch 8 inference:  12%|█▏        | 6/49 [00:00<00:02, 17.30it/s]
    Running batch 8 inference:  16%|█▋        | 8/49 [00:00<00:02, 17.19it/s]
    Running batch 8 inference:  20%|██        | 10/49 [00:00<00:02, 17.26it/s]
    Running batch 8 inference:  24%|██▍       | 12/49 [00:00<00:02, 17.11it/s]
    Running batch 8 inference:  29%|██▊       | 14/49 [00:00<00:02, 17.17it/s]
    Running batch 8 inference:  33%|███▎      | 16/49 [00:00<00:01, 17.11it/s]
    Running batch 8 inference:  37%|███▋      | 18/49 [00:01<00:01, 17.20it/s]
    Running batch 8 inference:  41%|████      | 20/49 [00:01<00:01, 17.20it/s]
    Running batch 8 inference:  45%|████▍     | 22/49 [00:01<00:01, 17.10it/s]
    Running batch 8 inference:  49%|████▉     | 24/49 [00:01<00:01, 16.90it/s]
    Running batch 8 inference:  53%|█████▎    | 26/49 [00:01<00:01, 16.82it/s]
    Running batch 8 inference:  57%|█████▋    | 28/49 [00:01<00:01, 16.69it/s]
    Running batch 8 inference:  61%|██████    | 30/49 [00:01<00:01, 16.55it/s]
    Running batch 8 inference:  65%|██████▌   | 32/49 [00:01<00:01, 16.54it/s]
    Running batch 8 inference:  69%|██████▉   | 34/49 [00:02<00:00, 16.52it/s]
    Running batch 8 inference:  73%|███████▎  | 36/49 [00:02<00:00, 16.49it/s]
    Running batch 8 inference:  78%|███████▊  | 38/49 [00:02<00:00, 16.50it/s]
    Running batch 8 inference:  82%|████████▏ | 40/49 [00:02<00:00, 16.51it/s]
    Running batch 8 inference:  86%|████████▌ | 42/49 [00:02<00:00, 16.61it/s]
    Running batch 8 inference:  90%|████████▉ | 44/49 [00:02<00:00, 16.55it/s]
    Running batch 8 inference:  94%|█████████▍| 46/49 [00:02<00:00, 16.56it/s]
    Running batch 8 inference:  98%|█████████▊| 48/49 [00:02<00:00, 16.52it/s]
                                                                              

    Total Ensemble Batches:  75%|███████▌  | 3/4 [00:08<00:02,  2.90s/it]
    Running batch 12 inference:   0%|          | 0/49 [00:00<?, ?it/s]
    Running batch 12 inference:   4%|▍         | 2/49 [00:00<00:02, 16.44it/s]
    Running batch 12 inference:   8%|▊         | 4/49 [00:00<00:02, 16.55it/s]
    Running batch 12 inference:  12%|█▏        | 6/49 [00:00<00:02, 16.51it/s]
    Running batch 12 inference:  16%|█▋        | 8/49 [00:00<00:02, 16.60it/s]
    Running batch 12 inference:  20%|██        | 10/49 [00:00<00:02, 16.52it/s]
    Running batch 12 inference:  24%|██▍       | 12/49 [00:00<00:02, 16.47it/s]
    Running batch 12 inference:  29%|██▊       | 14/49 [00:00<00:02, 17.25it/s]
    Running batch 12 inference:  33%|███▎      | 16/49 [00:00<00:01, 17.58it/s]
    Running batch 12 inference:  37%|███▋      | 18/49 [00:01<00:01, 17.79it/s]
    Running batch 12 inference:  41%|████      | 20/49 [00:01<00:01, 17.60it/s]
    Running batch 12 inference:  45%|████▍     | 22/49 [00:01<00:01, 17.21it/s]
    Running batch 12 inference:  49%|████▉     | 24/49 [00:01<00:01, 17.04it/s]
    Running batch 12 inference:  53%|█████▎    | 26/49 [00:01<00:01, 16.84it/s]
    Running batch 12 inference:  57%|█████▋    | 28/49 [00:01<00:01, 16.77it/s]
    Running batch 12 inference:  61%|██████    | 30/49 [00:01<00:01, 16.82it/s]
    Running batch 12 inference:  65%|██████▌   | 32/49 [00:01<00:01, 16.71it/s]
    Running batch 12 inference:  69%|██████▉   | 34/49 [00:02<00:00, 16.76it/s]
    Running batch 12 inference:  73%|███████▎  | 36/49 [00:02<00:00, 16.76it/s]
    Running batch 12 inference:  78%|███████▊  | 38/49 [00:02<00:00, 16.68it/s]
    Running batch 12 inference:  82%|████████▏ | 40/49 [00:02<00:00, 16.58it/s]
    Running batch 12 inference:  86%|████████▌ | 42/49 [00:02<00:00, 16.89it/s]
    Running batch 12 inference:  90%|████████▉ | 44/49 [00:02<00:00, 16.84it/s]
    Running batch 12 inference:  94%|█████████▍| 46/49 [00:02<00:00, 16.76it/s]
    Running batch 12 inference:  98%|█████████▊| 48/49 [00:02<00:00, 16.77it/s]
                                                                               

    Total Ensemble Batches: 100%|██████████| 4/4 [00:11<00:00,  2.90s/it]    Total Ensemble Batches: 100%|██████████| 4/4 [00:11<00:00,  2.90s/it]
    2026-01-27 22:49:00.797 | SUCCESS  | earth2studio.run:ensemble:438 - 
    Inference complete




.. GENERATED FROM PYTHON SOURCE LINES 148-153

Now let's introduce slight model perturbation using the prognostic model hooks defined
in :py:class:`earth2studio.models.px.utils.PrognosticMixin`.
Note that :py:obj:`center.unsqueeze(-1)` is DLWP specific since it operates on a cubed sphere
with grid dimensions (nface, lat, lon) instead of just (lat,lon).
To switch out the model, consider removing the :py:meth:`unsqueeze` .

.. GENERATED FROM PYTHON SOURCE LINES 155-183

.. code-block:: Python

    model.front_hook = lambda x, coords: (
        x
        - 0.1
        * x.var(dim=0)
        * (x - model.center.unsqueeze(-1))
        / (model.scale.unsqueeze(-1)) ** 2
        + 0.1 * (x - x.mean(dim=0)),
        coords,
    )
    # Also could use model.rear_hook = ...

    io_perturbed = ZarrBackend(
        file_name="outputs/05_ensemble_model_perturbation.zarr",
        chunks=chunks,
        backend_kwargs={"overwrite": True},
    )
    io_perturbed = ensemble(
        [forecast_date],
        nsteps,
        nensemble,
        model,
        data,
        io_perturbed,
        Gaussian(noise_amplitude=0.01),
        output_coords=output_coords,
        batch_size=batch_size,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    2026-01-27 22:49:00.801 | INFO     | earth2studio.run:ensemble:328 - Running ensemble inference!
    2026-01-27 22:49:00.801 | INFO     | earth2studio.run:ensemble:336 - Inference device: cuda
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]                                                            2026-01-27 22:49:00.888 | DEBUG    | earth2studio.data.gfs:fetch_array:382 - Fetching GFS grib file: noaa-gfs-bdp-pds/gfs.20240129/18/atmos/gfs.t18z.pgrb2.0p25.f000 402393843-1000454
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]                                                            2026-01-27 22:49:00.900 | DEBUG    | earth2studio.data.gfs:fetch_array:382 - Fetching GFS grib file: noaa-gfs-bdp-pds/gfs.20240129/18/atmos/gfs.t18z.pgrb2.0p25.f000 298404811-863710
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]                                                            2026-01-27 22:49:00.911 | DEBUG    | earth2studio.data.gfs:fetch_array:382 - Fetching GFS grib file: noaa-gfs-bdp-pds/gfs.20240129/18/atmos/gfs.t18z.pgrb2.0p25.f000 213960931-731790
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]                                                            2026-01-27 22:49:00.922 | DEBUG    | earth2studio.data.gfs:fetch_array:382 - Fetching GFS grib file: noaa-gfs-bdp-pds/gfs.20240129/18/atmos/gfs.t18z.pgrb2.0p25.f000 255947617-818002
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]                                                            2026-01-27 22:49:00.933 | DEBUG    | earth2studio.data.gfs:fetch_array:382 - Fetching GFS grib file: noaa-gfs-bdp-pds/gfs.20240129/18/atmos/gfs.t18z.pgrb2.0p25.f000 412982869-882301
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]                                                            2026-01-27 22:49:00.944 | DEBUG    | earth2studio.data.gfs:fetch_array:382 - Fetching GFS grib file: noaa-gfs-bdp-pds/gfs.20240129/18/atmos/gfs.t18z.pgrb2.0p25.f000 333455139-848796
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]                                                            2026-01-27 22:49:00.956 | DEBUG    | earth2studio.data.gfs:fetch_array:382 - Fetching GFS grib file: noaa-gfs-bdp-pds/gfs.20240129/18/atmos/gfs.t18z.pgrb2.0p25.f000 424587978-1175298
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]    Fetching GFS data: 100%|██████████| 7/7 [00:00<00:00, 88.79it/s]
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]                                                            2026-01-27 22:49:01.040 | DEBUG    | earth2studio.data.gfs:fetch_array:382 - Fetching GFS grib file: noaa-gfs-bdp-pds/gfs.20240130/00/atmos/gfs.t00z.pgrb2.0p25.f000 330480536-845677
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]                                                            2026-01-27 22:49:01.052 | DEBUG    | earth2studio.data.gfs:fetch_array:382 - Fetching GFS grib file: noaa-gfs-bdp-pds/gfs.20240130/00/atmos/gfs.t00z.pgrb2.0p25.f000 419044588-1178697
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]                                                            2026-01-27 22:49:01.063 | DEBUG    | earth2studio.data.gfs:fetch_array:382 - Fetching GFS grib file: noaa-gfs-bdp-pds/gfs.20240130/00/atmos/gfs.t00z.pgrb2.0p25.f000 397114008-995975
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]                                                            2026-01-27 22:49:01.074 | DEBUG    | earth2studio.data.gfs:fetch_array:382 - Fetching GFS grib file: noaa-gfs-bdp-pds/gfs.20240130/00/atmos/gfs.t00z.pgrb2.0p25.f000 214406883-731397
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]                                                            2026-01-27 22:49:01.085 | DEBUG    | earth2studio.data.gfs:fetch_array:382 - Fetching GFS grib file: noaa-gfs-bdp-pds/gfs.20240130/00/atmos/gfs.t00z.pgrb2.0p25.f000 256366833-813140
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]                                                            2026-01-27 22:49:01.096 | DEBUG    | earth2studio.data.gfs:fetch_array:382 - Fetching GFS grib file: noaa-gfs-bdp-pds/gfs.20240130/00/atmos/gfs.t00z.pgrb2.0p25.f000 297270945-860182
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]                                                            2026-01-27 22:49:01.107 | DEBUG    | earth2studio.data.gfs:fetch_array:382 - Fetching GFS grib file: noaa-gfs-bdp-pds/gfs.20240130/00/atmos/gfs.t00z.pgrb2.0p25.f000 407596993-877008
    Fetching GFS data:   0%|          | 0/7 [00:00<?, ?it/s]    Fetching GFS data: 100%|██████████| 7/7 [00:00<00:00, 89.49it/s]
    2026-01-27 22:49:01.147 | SUCCESS  | earth2studio.run:ensemble:358 - Fetched data from GFS
    2026-01-27 22:49:01.184 | INFO     | earth2studio.run:ensemble:386 - Starting 16 Member Ensemble Inference with             4 number of batches.


    Total Ensemble Batches:   0%|          | 0/4 [00:00<?, ?it/s]
    Running batch 0 inference:   0%|          | 0/49 [00:00<?, ?it/s]
    Running batch 0 inference:   6%|▌         | 3/49 [00:00<00:02, 22.02it/s]
    Running batch 0 inference:  12%|█▏        | 6/49 [00:00<00:02, 18.12it/s]
    Running batch 0 inference:  16%|█▋        | 8/49 [00:00<00:02, 17.61it/s]
    Running batch 0 inference:  20%|██        | 10/49 [00:00<00:02, 17.92it/s]
    Running batch 0 inference:  27%|██▋       | 13/49 [00:00<00:01, 19.55it/s]
    Running batch 0 inference:  33%|███▎      | 16/49 [00:00<00:01, 19.03it/s]
    Running batch 0 inference:  37%|███▋      | 18/49 [00:00<00:01, 18.53it/s]
    Running batch 0 inference:  41%|████      | 20/49 [00:01<00:01, 17.94it/s]
    Running batch 0 inference:  45%|████▍     | 22/49 [00:01<00:01, 17.47it/s]
    Running batch 0 inference:  49%|████▉     | 24/49 [00:01<00:01, 17.17it/s]
    Running batch 0 inference:  53%|█████▎    | 26/49 [00:01<00:01, 17.00it/s]
    Running batch 0 inference:  57%|█████▋    | 28/49 [00:01<00:01, 16.91it/s]
    Running batch 0 inference:  61%|██████    | 30/49 [00:01<00:01, 16.83it/s]
    Running batch 0 inference:  65%|██████▌   | 32/49 [00:01<00:01, 16.75it/s]
    Running batch 0 inference:  69%|██████▉   | 34/49 [00:01<00:00, 16.63it/s]
    Running batch 0 inference:  73%|███████▎  | 36/49 [00:02<00:00, 16.56it/s]
    Running batch 0 inference:  78%|███████▊  | 38/49 [00:02<00:00, 16.62it/s]
    Running batch 0 inference:  82%|████████▏ | 40/49 [00:02<00:00, 17.42it/s]
    Running batch 0 inference:  86%|████████▌ | 42/49 [00:02<00:00, 17.38it/s]
    Running batch 0 inference:  90%|████████▉ | 44/49 [00:02<00:00, 17.54it/s]
    Running batch 0 inference:  94%|█████████▍| 46/49 [00:02<00:00, 17.38it/s]
    Running batch 0 inference:  98%|█████████▊| 48/49 [00:02<00:00, 17.20it/s]
                                                                              

    Total Ensemble Batches:  25%|██▌       | 1/4 [00:02<00:08,  2.79s/it]
    Running batch 4 inference:   0%|          | 0/49 [00:00<?, ?it/s]
    Running batch 4 inference:   4%|▍         | 2/49 [00:00<00:02, 16.61it/s]
    Running batch 4 inference:   8%|▊         | 4/49 [00:00<00:02, 16.47it/s]
    Running batch 4 inference:  12%|█▏        | 6/49 [00:00<00:02, 16.48it/s]
    Running batch 4 inference:  16%|█▋        | 8/49 [00:00<00:02, 17.57it/s]
    Running batch 4 inference:  22%|██▏       | 11/49 [00:00<00:01, 20.82it/s]
    Running batch 4 inference:  29%|██▊       | 14/49 [00:00<00:01, 21.81it/s]
    Running batch 4 inference:  35%|███▍      | 17/49 [00:00<00:01, 21.77it/s]
    Running batch 4 inference:  41%|████      | 20/49 [00:01<00:01, 19.07it/s]
    Running batch 4 inference:  45%|████▍     | 22/49 [00:01<00:01, 18.42it/s]
    Running batch 4 inference:  49%|████▉     | 24/49 [00:01<00:01, 17.84it/s]
    Running batch 4 inference:  53%|█████▎    | 26/49 [00:01<00:01, 17.70it/s]
    Running batch 4 inference:  57%|█████▋    | 28/49 [00:01<00:01, 17.38it/s]
    Running batch 4 inference:  61%|██████    | 30/49 [00:01<00:01, 17.01it/s]
    Running batch 4 inference:  65%|██████▌   | 32/49 [00:01<00:01, 16.89it/s]
    Running batch 4 inference:  69%|██████▉   | 34/49 [00:01<00:00, 16.81it/s]
    Running batch 4 inference:  73%|███████▎  | 36/49 [00:02<00:00, 16.86it/s]
    Running batch 4 inference:  78%|███████▊  | 38/49 [00:02<00:00, 17.19it/s]
    Running batch 4 inference:  82%|████████▏ | 40/49 [00:02<00:00, 17.47it/s]
    Running batch 4 inference:  86%|████████▌ | 42/49 [00:02<00:00, 17.20it/s]
    Running batch 4 inference:  90%|████████▉ | 44/49 [00:02<00:00, 17.00it/s]
    Running batch 4 inference:  94%|█████████▍| 46/49 [00:02<00:00, 16.78it/s]
    Running batch 4 inference:  98%|█████████▊| 48/49 [00:02<00:00, 16.58it/s]
                                                                              

    Total Ensemble Batches:  50%|█████     | 2/4 [00:05<00:05,  2.77s/it]
    Running batch 8 inference:   0%|          | 0/49 [00:00<?, ?it/s]
    Running batch 8 inference:   4%|▍         | 2/49 [00:00<00:02, 16.52it/s]
    Running batch 8 inference:   8%|▊         | 4/49 [00:00<00:02, 16.64it/s]
    Running batch 8 inference:  12%|█▏        | 6/49 [00:00<00:02, 16.62it/s]
    Running batch 8 inference:  16%|█▋        | 8/49 [00:00<00:02, 16.62it/s]
    Running batch 8 inference:  20%|██        | 10/49 [00:00<00:02, 16.55it/s]
    Running batch 8 inference:  24%|██▍       | 12/49 [00:00<00:02, 17.43it/s]
    Running batch 8 inference:  29%|██▊       | 14/49 [00:00<00:02, 17.31it/s]
    Running batch 8 inference:  33%|███▎      | 16/49 [00:00<00:01, 16.95it/s]
    Running batch 8 inference:  37%|███▋      | 18/49 [00:01<00:01, 16.86it/s]
    Running batch 8 inference:  41%|████      | 20/49 [00:01<00:01, 16.80it/s]
    Running batch 8 inference:  45%|████▍     | 22/49 [00:01<00:01, 16.67it/s]
    Running batch 8 inference:  49%|████▉     | 24/49 [00:01<00:01, 16.65it/s]
    Running batch 8 inference:  53%|█████▎    | 26/49 [00:01<00:01, 16.63it/s]
    Running batch 8 inference:  57%|█████▋    | 28/49 [00:01<00:01, 16.78it/s]
    Running batch 8 inference:  61%|██████    | 30/49 [00:01<00:01, 16.71it/s]
    Running batch 8 inference:  65%|██████▌   | 32/49 [00:01<00:01, 16.68it/s]
    Running batch 8 inference:  69%|██████▉   | 34/49 [00:02<00:00, 16.61it/s]
    Running batch 8 inference:  73%|███████▎  | 36/49 [00:02<00:00, 16.66it/s]
    Running batch 8 inference:  78%|███████▊  | 38/49 [00:02<00:00, 16.90it/s]
    Running batch 8 inference:  82%|████████▏ | 40/49 [00:02<00:00, 16.91it/s]
    Running batch 8 inference:  86%|████████▌ | 42/49 [00:02<00:00, 16.86it/s]
    Running batch 8 inference:  90%|████████▉ | 44/49 [00:02<00:00, 16.68it/s]
    Running batch 8 inference:  94%|█████████▍| 46/49 [00:02<00:00, 17.10it/s]
    Running batch 8 inference:  98%|█████████▊| 48/49 [00:02<00:00, 17.05it/s]
                                                                              

    Total Ensemble Batches:  75%|███████▌  | 3/4 [00:08<00:02,  2.83s/it]
    Running batch 12 inference:   0%|          | 0/49 [00:00<?, ?it/s]
    Running batch 12 inference:   4%|▍         | 2/49 [00:00<00:02, 16.36it/s]
    Running batch 12 inference:   8%|▊         | 4/49 [00:00<00:02, 16.36it/s]
    Running batch 12 inference:  14%|█▍        | 7/49 [00:00<00:02, 19.28it/s]
    Running batch 12 inference:  18%|█▊        | 9/49 [00:00<00:02, 18.67it/s]
    Running batch 12 inference:  22%|██▏       | 11/49 [00:00<00:02, 18.10it/s]
    Running batch 12 inference:  27%|██▋       | 13/49 [00:00<00:02, 17.68it/s]
    Running batch 12 inference:  31%|███       | 15/49 [00:00<00:01, 17.51it/s]
    Running batch 12 inference:  35%|███▍      | 17/49 [00:00<00:01, 17.20it/s]
    Running batch 12 inference:  39%|███▉      | 19/49 [00:01<00:01, 16.91it/s]
    Running batch 12 inference:  43%|████▎     | 21/49 [00:01<00:01, 16.82it/s]
    Running batch 12 inference:  47%|████▋     | 23/49 [00:01<00:01, 16.66it/s]
    Running batch 12 inference:  51%|█████     | 25/49 [00:01<00:01, 16.58it/s]
    Running batch 12 inference:  55%|█████▌    | 27/49 [00:01<00:01, 16.55it/s]
    Running batch 12 inference:  59%|█████▉    | 29/49 [00:01<00:01, 16.52it/s]
    Running batch 12 inference:  63%|██████▎   | 31/49 [00:01<00:01, 16.88it/s]
    Running batch 12 inference:  67%|██████▋   | 33/49 [00:01<00:00, 16.84it/s]
    Running batch 12 inference:  71%|███████▏  | 35/49 [00:02<00:00, 16.72it/s]
    Running batch 12 inference:  76%|███████▌  | 37/49 [00:02<00:00, 16.72it/s]
    Running batch 12 inference:  80%|███████▉  | 39/49 [00:02<00:00, 16.69it/s]
    Running batch 12 inference:  84%|████████▎ | 41/49 [00:02<00:00, 16.64it/s]
    Running batch 12 inference:  88%|████████▊ | 43/49 [00:02<00:00, 16.63it/s]
    Running batch 12 inference:  92%|█████████▏| 45/49 [00:02<00:00, 16.69it/s]
    Running batch 12 inference:  96%|█████████▌| 47/49 [00:02<00:00, 17.03it/s]
    Running batch 12 inference: 100%|██████████| 49/49 [00:02<00:00, 17.13it/s]
                                                                               

    Total Ensemble Batches: 100%|██████████| 4/4 [00:11<00:00,  2.85s/it]    Total Ensemble Batches: 100%|██████████| 4/4 [00:11<00:00,  2.83s/it]
    2026-01-27 22:49:12.506 | SUCCESS  | earth2studio.run:ensemble:438 - 
    Inference complete




.. GENERATED FROM PYTHON SOURCE LINES 184-191

Post Processing
---------------
The last step is to post process our results.
Here we plot and compare the ensemble mean and standard deviation from using an
unperturbed/perturbed model.

Notice that the Zarr IO function has additional APIs to interact with the stored data.

.. GENERATED FROM PYTHON SOURCE LINES 193-328

.. code-block:: Python

    import cartopy.crs as ccrs
    import matplotlib.pyplot as plt
    from matplotlib.colors import LogNorm

    levels_unperturbed = np.linspace(0, io_unperturbed["tcwv"][:].max())
    levels_perturbed = np.linspace(0, io_perturbed["tcwv"][:].max())


    std_levels_perturbed = np.linspace(0, io_perturbed["tcwv"][:].std(axis=0).max())

    plt.close("all")
    fig = plt.figure(figsize=(20, 10), tight_layout=True)
    ax0 = fig.add_subplot(2, 2, 1, projection=ccrs.PlateCarree())
    ax1 = fig.add_subplot(2, 2, 2, projection=ccrs.PlateCarree())
    ax2 = fig.add_subplot(2, 2, 3, projection=ccrs.PlateCarree())
    ax3 = fig.add_subplot(2, 2, 4, projection=ccrs.PlateCarree())


    def update(frame):
        """This function updates the frame with a new lead time for animation."""
        import warnings

        warnings.filterwarnings("ignore")
        ax0.clear()
        ax1.clear()
        ax2.clear()
        ax3.clear()

        ## Update unperturbed image
        im0 = ax0.contourf(
            io_unperturbed["lon"][:],
            io_unperturbed["lat"][:],
            io_unperturbed["tcwv"][:, 0, frame].mean(axis=0),
            transform=ccrs.PlateCarree(),
            cmap="Blues",
            levels=levels_unperturbed,
        )
        ax0.coastlines()
        ax0.gridlines()

        im1 = ax1.contourf(
            io_unperturbed["lon"][:],
            io_unperturbed["lat"][:],
            io_unperturbed["tcwv"][:, 0, frame].std(axis=0),
            transform=ccrs.PlateCarree(),
            cmap="RdPu",
            levels=std_levels_perturbed,
            norm=LogNorm(vmin=1e-1, vmax=std_levels_perturbed[-1]),
        )
        ax1.coastlines()
        ax1.gridlines()

        im2 = ax2.contourf(
            io_perturbed["lon"][:],
            io_perturbed["lat"][:],
            io_perturbed["tcwv"][:, 0, frame].mean(axis=0),
            transform=ccrs.PlateCarree(),
            cmap="Blues",
            levels=levels_perturbed,
        )
        ax2.coastlines()
        ax2.gridlines()

        im3 = ax3.contourf(
            io_perturbed["lon"][:],
            io_perturbed["lat"][:],
            io_perturbed["tcwv"][:, 0, frame].std(axis=0),
            transform=ccrs.PlateCarree(),
            cmap="RdPu",
            levels=std_levels_perturbed,
            norm=LogNorm(vmin=1e-1, vmax=std_levels_perturbed[-1]),
        )
        ax3.coastlines()
        ax3.gridlines()

        for i in range(16):
            ax0.contour(
                io_unperturbed["lon"][:],
                io_unperturbed["lat"][:],
                io_unperturbed["z500"][i, 0, frame] / 100.0,
                transform=ccrs.PlateCarree(),
                levels=np.arange(485, 580, 15),
                colors="black",
                linestyle="dashed",
            )

            ax2.contour(
                io_perturbed["lon"][:],
                io_perturbed["lat"][:],
                io_perturbed["z500"][i, 0, frame] / 100.0,
                transform=ccrs.PlateCarree(),
                levels=np.arange(485, 580, 15),
                colors="black",
                linestyle="dashed",
            )
        plt.suptitle(
            f'Forecast Starting on {forecast_date} - Lead Time - {io_perturbed["lead_time"][frame]}'
        )

        ax0.set_title("Unperturbed Ensemble Mean - tcwv + z500 countors")
        ax1.set_title("Unperturbed Ensemble Std - tcwv")
        ax2.set_title("Perturbed Ensemble Mean - tcwv + z500 contours")
        ax3.set_title("Perturbed Ensemble Std - tcwv")

        if frame == 0:
            plt.colorbar(
                im0, ax=ax0, shrink=0.75, pad=0.04, label="kg m^-2", format="%2.1f"
            )
            plt.colorbar(
                im1, ax=ax1, shrink=0.75, pad=0.04, label="kg m^-2", format="%1.2e"
            )
            plt.colorbar(
                im2, ax=ax2, shrink=0.75, pad=0.04, label="kg m^-2", format="%2.1f"
            )
            plt.colorbar(
                im3, ax=ax3, shrink=0.75, pad=0.04, label="kg m^-2", format="%1.2e"
            )


    # Uncomment this for animation
    # import matplotlib.animation as animation
    # update(0)
    # ani = animation.FuncAnimation(
    # fig=fig, func=update, frames=range(1, nsteps), cache_frame_data=False
    # )
    # ani.save(f"outputs/05_model_perturbation_{forecast_date}.gif", dpi=300)


    for lt in [10, 20, 30, 40]:
        update(lt)
        plt.savefig(
            f"outputs/05_model_perturbation_{forecast_date}_leadtime_{lt}.png",
            dpi=300,
            bbox_inches="tight",
        )



.. image-sg:: /examples/images/sphx_glr_06_model_perturbation_hook_001.png
   :alt: Forecast Starting on 2024-01-30 - Lead Time - 240 hours, Unperturbed Ensemble Mean - tcwv + z500 countors, Unperturbed Ensemble Std - tcwv, Perturbed Ensemble Mean - tcwv + z500 contours, Perturbed Ensemble Std - tcwv
   :srcset: /examples/images/sphx_glr_06_model_perturbation_hook_001.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 39.991 seconds)


.. _sphx_glr_download_examples_06_model_perturbation_hook.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: 06_model_perturbation_hook.ipynb <06_model_perturbation_hook.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: 06_model_perturbation_hook.py <06_model_perturbation_hook.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: 06_model_perturbation_hook.zip <06_model_perturbation_hook.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
