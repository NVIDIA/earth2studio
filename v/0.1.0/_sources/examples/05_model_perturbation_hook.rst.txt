
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "examples/05_model_perturbation_hook.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_examples_05_model_perturbation_hook.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_05_model_perturbation_hook.py:


Model Hook Injection: Perturbation
==========================

Adding model noise by using custom hooks.

This example will demonstrate how to run an ensemble inference workflow to generate a
perturbed ensemble forecast. This perturbation is done by injecting code into the model
front and rear hooks.
These hooks are applied to the tensor data before/after the model forward call.

This example also illustrates how you can subselect data for IO. In this example we
will only output two variables:
total column water vapor (tcwv) and 500 hPa geopotential (z500).
To run this, make sure that the model selected predicts these variables are change
appropriately.

In this example you will learn:

- How to instantiate a built in prognostic model
- Creating a data source and IO object
- Changing the model forward/rear hooks
- Choose a subselection of coordinates to save to an IO object.
- Post-processing results

.. GENERATED FROM PYTHON SOURCE LINES 45-64

Creating an Ensemble Workflow
-----------------------------------

To start let's begin with creating an ensemble workflow to use. We encourage
users to explore and experiment with their own custom workflows that borrow ideas from
built in workflows inside :py:obj:`earth2studio.run` or the examples.

Creating our own generalizable ensemble workflow is easy when we rely on the component
interfaces defined in Earth2Studio (use dependency injection). Here we create a run
method that accepts the following:

- time: Input list of datetimes / strings to run inference for
- nsteps: Number of forecast steps to predict
- nensemble: Number of ensembles to run for
- prognostic: Our initialized prognostic model
- data: Initialized data source to fetch initial conditions from
- io: io store that data is written to.
- output_coords: CoordSystem of output coordinates that should be saved. Should be
     a proper subset of model output coordinates.

.. GENERATED FROM PYTHON SOURCE LINES 66-80

Set Up
------
With the ensemble workflow defined, we now need to create the individual components.

We need the following:

- Prognostic Model: Use the built in DLWP model :py:class:`earth2studio.models.px.DLWP`.
- Datasource: Pull data from the GFS data api :py:class:`earth2studio.data.GFS`.
- IO Backend: Save the outputs into a Zarr store :py:class:`earth2studio.io.ZarrBackend`.

We will first run the ensemble workflow using an unmodified function, that is a model that has the
default (identity) forward and rear hooks. Then we will define new hooks for the model and rerun the
inference request.
%%

.. GENERATED FROM PYTHON SOURCE LINES 80-105

.. code-block:: Python


    from dotenv import load_dotenv

    load_dotenv()  # TODO: make common example prep function

    import numpy as np

    from earth2studio.data import GFS
    from earth2studio.io import ZarrBackend
    from earth2studio.models.px import DLWP
    from earth2studio.perturbation import Gaussian
    from earth2studio.run import ensemble

    # Load the default model package which downloads the check point from NGC
    package = DLWP.load_default_package()
    model = DLWP.load_model(package)

    # Create the data source
    data = GFS()

    # Create the IO handler, store in memory
    chunks = {"ensemble": 1, "time": 1}
    io_unperturbed = ZarrBackend(file_name="outputs/05_ensemble.zarr", chunks=chunks)









.. GENERATED FROM PYTHON SOURCE LINES 106-114

Execute the Workflow
--------------------
First, we will run the ensemble workflow but with a :py:meth:`earth2studio.perturbation.Gaussian`
perturbation as the control.

The workflow will return the provided IO object back to the user, which can be used to
then post process. Some have additional APIs that can be handy for post-processing or
saving to file. Check the API docs for more information.

.. GENERATED FROM PYTHON SOURCE LINES 116-139

.. code-block:: Python

    nsteps = 4 * 12
    nensemble = 16
    batch_size = 4
    forecast_date = "2024-01-30"
    output_coords = {
        "lat": np.arange(25.0, 60.0, 0.25),
        "lon": np.arange(230.0, 300.0, 0.25),
        "variable": np.array(["tcwv", "z500"]),
    }

    # First run with no model perturbation
    io_unperturbed = ensemble(
        [forecast_date],
        nsteps,
        nensemble,
        model,
        data,
        io_unperturbed,
        Gaussian(noise_amplitude=0.01),
        output_coords=output_coords,
        batch_size=batch_size,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    2024-04-19 00:31:08.955 | INFO     | earth2studio.run:ensemble:157 - Running ensemble inference!
    2024-04-19 00:31:08.955 | INFO     | earth2studio.run:ensemble:165 - Inference device: cuda
    2024-04-19 00:31:08.962 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:151 - Fetching GFS index file: 2024-01-29 18:00:00
    Fetching GFS for 2024-01-29 18:00:00:   0%|          | 0/7 [00:00<?, ?it/s]                                                                               2024-04-19 00:31:09.366 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:197 - Fetching GFS grib file for variable: t850 at 2024-01-29 18:00:00
    Fetching GFS for 2024-01-29 18:00:00:   0%|          | 0/7 [00:00<?, ?it/s]    Fetching GFS for 2024-01-29 18:00:00:  14%|█▍        | 1/7 [00:05<00:35,  5.98s/it]                                                                                       2024-04-19 00:31:15.351 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:197 - Fetching GFS grib file for variable: z1000 at 2024-01-29 18:00:00
    Fetching GFS for 2024-01-29 18:00:00:  14%|█▍        | 1/7 [00:05<00:35,  5.98s/it]    Fetching GFS for 2024-01-29 18:00:00:  29%|██▊       | 2/7 [00:09<00:23,  4.75s/it]                                                                                       2024-04-19 00:31:19.229 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:197 - Fetching GFS grib file for variable: z700 at 2024-01-29 18:00:00
    Fetching GFS for 2024-01-29 18:00:00:  29%|██▊       | 2/7 [00:09<00:23,  4.75s/it]    Fetching GFS for 2024-01-29 18:00:00:  43%|████▎     | 3/7 [00:13<00:16,  4.15s/it]                                                                                       2024-04-19 00:31:22.673 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:197 - Fetching GFS grib file for variable: z500 at 2024-01-29 18:00:00
    Fetching GFS for 2024-01-29 18:00:00:  43%|████▎     | 3/7 [00:13<00:16,  4.15s/it]    Fetching GFS for 2024-01-29 18:00:00:  57%|█████▋    | 4/7 [00:16<00:11,  3.70s/it]                                                                                       2024-04-19 00:31:25.686 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:197 - Fetching GFS grib file for variable: z300 at 2024-01-29 18:00:00
    Fetching GFS for 2024-01-29 18:00:00:  57%|█████▋    | 4/7 [00:16<00:11,  3.70s/it]    Fetching GFS for 2024-01-29 18:00:00:  71%|███████▏  | 5/7 [00:19<00:06,  3.39s/it]                                                                                       2024-04-19 00:31:28.536 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:197 - Fetching GFS grib file for variable: tcwv at 2024-01-29 18:00:00
    Fetching GFS for 2024-01-29 18:00:00:  71%|███████▏  | 5/7 [00:19<00:06,  3.39s/it]    Fetching GFS for 2024-01-29 18:00:00:  86%|████████▌ | 6/7 [00:22<00:03,  3.35s/it]                                                                                       2024-04-19 00:31:31.804 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:197 - Fetching GFS grib file for variable: t2m at 2024-01-29 18:00:00
    Fetching GFS for 2024-01-29 18:00:00:  86%|████████▌ | 6/7 [00:22<00:03,  3.35s/it]    Fetching GFS for 2024-01-29 18:00:00: 100%|██████████| 7/7 [00:25<00:00,  3.34s/it]    Fetching GFS for 2024-01-29 18:00:00: 100%|██████████| 7/7 [00:25<00:00,  3.68s/it]
    2024-04-19 00:31:35.140 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:151 - Fetching GFS index file: 2024-01-30 00:00:00
    Fetching GFS for 2024-01-30 00:00:00:   0%|          | 0/7 [00:00<?, ?it/s]                                                                               2024-04-19 00:31:35.238 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:197 - Fetching GFS grib file for variable: t850 at 2024-01-30 00:00:00
    Fetching GFS for 2024-01-30 00:00:00:   0%|          | 0/7 [00:00<?, ?it/s]    Fetching GFS for 2024-01-30 00:00:00:  14%|█▍        | 1/7 [00:02<00:17,  2.99s/it]                                                                                       2024-04-19 00:31:38.225 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:197 - Fetching GFS grib file for variable: z1000 at 2024-01-30 00:00:00
    Fetching GFS for 2024-01-30 00:00:00:  14%|█▍        | 1/7 [00:02<00:17,  2.99s/it]    Fetching GFS for 2024-01-30 00:00:00:  29%|██▊       | 2/7 [00:06<00:15,  3.05s/it]                                                                                       2024-04-19 00:31:41.327 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:197 - Fetching GFS grib file for variable: z700 at 2024-01-30 00:00:00
    Fetching GFS for 2024-01-30 00:00:00:  29%|██▊       | 2/7 [00:06<00:15,  3.05s/it]    Fetching GFS for 2024-01-30 00:00:00:  43%|████▎     | 3/7 [00:08<00:11,  2.90s/it]                                                                                       2024-04-19 00:31:44.045 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:197 - Fetching GFS grib file for variable: z500 at 2024-01-30 00:00:00
    Fetching GFS for 2024-01-30 00:00:00:  43%|████▎     | 3/7 [00:08<00:11,  2.90s/it]    Fetching GFS for 2024-01-30 00:00:00:  57%|█████▋    | 4/7 [00:11<00:08,  2.74s/it]                                                                                       2024-04-19 00:31:46.542 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:197 - Fetching GFS grib file for variable: z300 at 2024-01-30 00:00:00
    Fetching GFS for 2024-01-30 00:00:00:  57%|█████▋    | 4/7 [00:11<00:08,  2.74s/it]    Fetching GFS for 2024-01-30 00:00:00:  71%|███████▏  | 5/7 [00:13<00:05,  2.54s/it]                                                                                       2024-04-19 00:31:48.724 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:197 - Fetching GFS grib file for variable: tcwv at 2024-01-30 00:00:00
    Fetching GFS for 2024-01-30 00:00:00:  71%|███████▏  | 5/7 [00:13<00:05,  2.54s/it]    Fetching GFS for 2024-01-30 00:00:00:  86%|████████▌ | 6/7 [00:15<00:02,  2.36s/it]                                                                                       2024-04-19 00:31:50.728 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:197 - Fetching GFS grib file for variable: t2m at 2024-01-30 00:00:00
    Fetching GFS for 2024-01-30 00:00:00:  86%|████████▌ | 6/7 [00:15<00:02,  2.36s/it]    Fetching GFS for 2024-01-30 00:00:00: 100%|██████████| 7/7 [00:16<00:00,  2.05s/it]    Fetching GFS for 2024-01-30 00:00:00: 100%|██████████| 7/7 [00:16<00:00,  2.42s/it]
    2024-04-19 00:31:52.188 | SUCCESS  | earth2studio.run:ensemble:177 - Fetched data from GFS
    2024-04-19 00:31:52.193 | INFO     | earth2studio.run:ensemble:196 - Starting 16 Member Ensemble Inference with             4 number of batches.
    Total Ensemble Batches:   0%|          | 0/4 [00:00<?, ?it/s]
    Running batch 0 inference:   0%|          | 0/49 [00:00<?, ?it/s]
    Running batch 0 inference:   6%|▌         | 3/49 [00:00<00:01, 29.85it/s]
    Running batch 0 inference:  12%|█▏        | 6/49 [00:00<00:01, 24.62it/s]
    Running batch 0 inference:  18%|█▊        | 9/49 [00:00<00:01, 22.54it/s]
    Running batch 0 inference:  24%|██▍       | 12/49 [00:00<00:01, 20.54it/s]
    Running batch 0 inference:  31%|███       | 15/49 [00:00<00:01, 19.81it/s]
    Running batch 0 inference:  37%|███▋      | 18/49 [00:00<00:01, 18.48it/s]
    Running batch 0 inference:  41%|████      | 20/49 [00:01<00:01, 17.92it/s]
    Running batch 0 inference:  45%|████▍     | 22/49 [00:01<00:01, 17.44it/s]
    Running batch 0 inference:  49%|████▉     | 24/49 [00:01<00:01, 17.12it/s]
    Running batch 0 inference:  53%|█████▎    | 26/49 [00:01<00:01, 16.48it/s]
    Running batch 0 inference:  57%|█████▋    | 28/49 [00:01<00:01, 15.84it/s]
    Running batch 0 inference:  61%|██████    | 30/49 [00:01<00:01, 15.32it/s]
    Running batch 0 inference:  65%|██████▌   | 32/49 [00:01<00:01, 14.78it/s]
    Running batch 0 inference:  69%|██████▉   | 34/49 [00:01<00:01, 14.64it/s]
    Running batch 0 inference:  73%|███████▎  | 36/49 [00:02<00:00, 14.46it/s]
    Running batch 0 inference:  78%|███████▊  | 38/49 [00:02<00:00, 14.09it/s]
    Running batch 0 inference:  82%|████████▏ | 40/49 [00:02<00:00, 13.76it/s]
    Running batch 0 inference:  86%|████████▌ | 42/49 [00:02<00:00, 13.67it/s]
    Running batch 0 inference:  90%|████████▉ | 44/49 [00:02<00:00, 13.15it/s]
    Running batch 0 inference:  94%|█████████▍| 46/49 [00:02<00:00, 12.84it/s]
    Running batch 0 inference:  98%|█████████▊| 48/49 [00:03<00:00, 12.81it/s]
                                                                                  Total Ensemble Batches:  25%|██▌       | 1/4 [00:03<00:09,  3.13s/it]
    Running batch 4 inference:   0%|          | 0/49 [00:00<?, ?it/s]
    Running batch 4 inference:   6%|▌         | 3/49 [00:00<00:01, 29.77it/s]
    Running batch 4 inference:  12%|█▏        | 6/49 [00:00<00:01, 24.99it/s]
    Running batch 4 inference:  18%|█▊        | 9/49 [00:00<00:01, 25.08it/s]
    Running batch 4 inference:  24%|██▍       | 12/49 [00:00<00:01, 23.12it/s]
    Running batch 4 inference:  31%|███       | 15/49 [00:00<00:01, 22.34it/s]
    Running batch 4 inference:  37%|███▋      | 18/49 [00:00<00:01, 20.08it/s]
    Running batch 4 inference:  43%|████▎     | 21/49 [00:00<00:01, 20.36it/s]
    Running batch 4 inference:  49%|████▉     | 24/49 [00:01<00:01, 19.33it/s]
    Running batch 4 inference:  53%|█████▎    | 26/49 [00:01<00:01, 19.19it/s]
    Running batch 4 inference:  57%|█████▋    | 28/49 [00:01<00:01, 18.90it/s]
    Running batch 4 inference:  61%|██████    | 30/49 [00:01<00:01, 17.41it/s]
    Running batch 4 inference:  65%|██████▌   | 32/49 [00:01<00:01, 16.49it/s]
    Running batch 4 inference:  69%|██████▉   | 34/49 [00:01<00:00, 15.51it/s]
    Running batch 4 inference:  73%|███████▎  | 36/49 [00:01<00:00, 15.07it/s]
    Running batch 4 inference:  78%|███████▊  | 38/49 [00:02<00:00, 14.16it/s]
    Running batch 4 inference:  82%|████████▏ | 40/49 [00:02<00:00, 13.17it/s]
    Running batch 4 inference:  86%|████████▌ | 42/49 [00:02<00:00, 12.92it/s]
    Running batch 4 inference:  90%|████████▉ | 44/49 [00:02<00:00, 12.58it/s]
    Running batch 4 inference:  94%|█████████▍| 46/49 [00:02<00:00, 12.47it/s]
    Running batch 4 inference:  98%|█████████▊| 48/49 [00:02<00:00, 12.49it/s]
                                                                                  Total Ensemble Batches:  50%|█████     | 2/4 [00:06<00:06,  3.06s/it]
    Running batch 8 inference:   0%|          | 0/49 [00:00<?, ?it/s]
    Running batch 8 inference:   8%|▊         | 4/49 [00:00<00:01, 26.90it/s]
    Running batch 8 inference:  14%|█▍        | 7/49 [00:00<00:01, 24.70it/s]
    Running batch 8 inference:  20%|██        | 10/49 [00:00<00:01, 21.83it/s]
    Running batch 8 inference:  27%|██▋       | 13/49 [00:00<00:01, 20.72it/s]
    Running batch 8 inference:  33%|███▎      | 16/49 [00:00<00:01, 19.49it/s]
    Running batch 8 inference:  37%|███▋      | 18/49 [00:00<00:01, 18.99it/s]
    Running batch 8 inference:  41%|████      | 20/49 [00:00<00:01, 18.54it/s]
    Running batch 8 inference:  45%|████▍     | 22/49 [00:01<00:01, 18.38it/s]
    Running batch 8 inference:  49%|████▉     | 24/49 [00:01<00:01, 17.89it/s]
    Running batch 8 inference:  53%|█████▎    | 26/49 [00:01<00:01, 17.37it/s]
    Running batch 8 inference:  57%|█████▋    | 28/49 [00:01<00:01, 16.89it/s]
    Running batch 8 inference:  61%|██████    | 30/49 [00:01<00:01, 16.37it/s]
    Running batch 8 inference:  65%|██████▌   | 32/49 [00:01<00:01, 16.03it/s]
    Running batch 8 inference:  69%|██████▉   | 34/49 [00:01<00:00, 15.54it/s]
    Running batch 8 inference:  73%|███████▎  | 36/49 [00:02<00:00, 14.78it/s]
    Running batch 8 inference:  78%|███████▊  | 38/49 [00:02<00:00, 14.03it/s]
    Running batch 8 inference:  82%|████████▏ | 40/49 [00:02<00:00, 13.71it/s]
    Running batch 8 inference:  86%|████████▌ | 42/49 [00:02<00:00, 13.29it/s]
    Running batch 8 inference:  90%|████████▉ | 44/49 [00:02<00:00, 13.57it/s]
    Running batch 8 inference:  94%|█████████▍| 46/49 [00:02<00:00, 13.67it/s]
    Running batch 8 inference:  98%|█████████▊| 48/49 [00:02<00:00, 13.24it/s]
                                                                                  Total Ensemble Batches:  75%|███████▌  | 3/4 [00:09<00:03,  3.05s/it]
    Running batch 12 inference:   0%|          | 0/49 [00:00<?, ?it/s]
    Running batch 12 inference:   8%|▊         | 4/49 [00:00<00:01, 26.08it/s]
    Running batch 12 inference:  14%|█▍        | 7/49 [00:00<00:01, 24.31it/s]
    Running batch 12 inference:  20%|██        | 10/49 [00:00<00:01, 21.46it/s]
    Running batch 12 inference:  27%|██▋       | 13/49 [00:00<00:01, 20.97it/s]
    Running batch 12 inference:  33%|███▎      | 16/49 [00:00<00:01, 19.30it/s]
    Running batch 12 inference:  37%|███▋      | 18/49 [00:00<00:01, 18.70it/s]
    Running batch 12 inference:  41%|████      | 20/49 [00:01<00:01, 18.19it/s]
    Running batch 12 inference:  45%|████▍     | 22/49 [00:01<00:01, 17.72it/s]
    Running batch 12 inference:  49%|████▉     | 24/49 [00:01<00:01, 17.38it/s]
    Running batch 12 inference:  53%|█████▎    | 26/49 [00:01<00:01, 16.75it/s]
    Running batch 12 inference:  57%|█████▋    | 28/49 [00:01<00:01, 16.08it/s]
    Running batch 12 inference:  61%|██████    | 30/49 [00:01<00:01, 15.70it/s]
    Running batch 12 inference:  65%|██████▌   | 32/49 [00:01<00:01, 14.96it/s]
    Running batch 12 inference:  69%|██████▉   | 34/49 [00:01<00:01, 14.61it/s]
    Running batch 12 inference:  73%|███████▎  | 36/49 [00:02<00:00, 14.45it/s]
    Running batch 12 inference:  78%|███████▊  | 38/49 [00:02<00:00, 14.10it/s]
    Running batch 12 inference:  82%|████████▏ | 40/49 [00:02<00:00, 13.48it/s]
    Running batch 12 inference:  86%|████████▌ | 42/49 [00:02<00:00, 12.92it/s]
    Running batch 12 inference:  90%|████████▉ | 44/49 [00:02<00:00, 12.61it/s]
    Running batch 12 inference:  94%|█████████▍| 46/49 [00:02<00:00, 12.30it/s]
    Running batch 12 inference:  98%|█████████▊| 48/49 [00:03<00:00, 12.07it/s]
                                                                                   Total Ensemble Batches: 100%|██████████| 4/4 [00:12<00:00,  3.10s/it]    Total Ensemble Batches: 100%|██████████| 4/4 [00:12<00:00,  3.09s/it]
    2024-04-19 00:32:04.550 | SUCCESS  | earth2studio.run:ensemble:242 - Ensemble Inference complete




.. GENERATED FROM PYTHON SOURCE LINES 140-145

Now let's introduce slight model perturbation using the prognostic model hooks defined
in :py:class:`earth2studio.models.px.utils.PrognosticMixin`.
Note that :py:obj:`center.unsqueeze(-1)` is DLWP specific since it operates on a cubed sphere
with grid dimensions (nface, lat, lon) instead of just (lat,lon).
To switch out the model, consider removing the :py:meth:`unsqueeze` .

.. GENERATED FROM PYTHON SOURCE LINES 147-173

.. code-block:: Python

    model.front_hook = lambda x, coords: (
        x
        - 0.1
        * x.var(dim=0)
        * (x - model.center.unsqueeze(-1))
        / (model.scale.unsqueeze(-1)) ** 2
        + 0.1 * (x - x.mean(dim=0)),
        coords,
    )
    # Also could use model.rear_hook = ...

    io_perturbed = ZarrBackend(
        file_name="outputs/05_ensemble_model_perturbation.zarr", chunks=chunks
    )
    io_perturbed = ensemble(
        [forecast_date],
        nsteps,
        nensemble,
        model,
        data,
        io_perturbed,
        Gaussian(noise_amplitude=0.01),
        output_coords=output_coords,
        batch_size=batch_size,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    2024-04-19 00:32:04.554 | INFO     | earth2studio.run:ensemble:157 - Running ensemble inference!
    2024-04-19 00:32:04.555 | INFO     | earth2studio.run:ensemble:165 - Inference device: cuda
    2024-04-19 00:32:04.555 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:151 - Fetching GFS index file: 2024-01-29 18:00:00
    Fetching GFS for 2024-01-29 18:00:00:   0%|          | 0/7 [00:00<?, ?it/s]                                                                               2024-04-19 00:32:04.923 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:197 - Fetching GFS grib file for variable: t850 at 2024-01-29 18:00:00
    Fetching GFS for 2024-01-29 18:00:00:   0%|          | 0/7 [00:00<?, ?it/s]                                                                               2024-04-19 00:32:04.946 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:197 - Fetching GFS grib file for variable: z1000 at 2024-01-29 18:00:00
    Fetching GFS for 2024-01-29 18:00:00:   0%|          | 0/7 [00:00<?, ?it/s]                                                                               2024-04-19 00:32:04.966 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:197 - Fetching GFS grib file for variable: z700 at 2024-01-29 18:00:00
    Fetching GFS for 2024-01-29 18:00:00:   0%|          | 0/7 [00:00<?, ?it/s]                                                                               2024-04-19 00:32:04.985 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:197 - Fetching GFS grib file for variable: z500 at 2024-01-29 18:00:00
    Fetching GFS for 2024-01-29 18:00:00:   0%|          | 0/7 [00:00<?, ?it/s]                                                                               2024-04-19 00:32:05.004 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:197 - Fetching GFS grib file for variable: z300 at 2024-01-29 18:00:00
    Fetching GFS for 2024-01-29 18:00:00:   0%|          | 0/7 [00:00<?, ?it/s]    Fetching GFS for 2024-01-29 18:00:00:  71%|███████▏  | 5/7 [00:00<00:00, 49.98it/s]                                                                                       2024-04-19 00:32:05.023 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:197 - Fetching GFS grib file for variable: tcwv at 2024-01-29 18:00:00
    Fetching GFS for 2024-01-29 18:00:00:  71%|███████▏  | 5/7 [00:00<00:00, 49.98it/s]                                                                                       2024-04-19 00:32:05.042 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:197 - Fetching GFS grib file for variable: t2m at 2024-01-29 18:00:00
    Fetching GFS for 2024-01-29 18:00:00:  71%|███████▏  | 5/7 [00:00<00:00, 49.98it/s]    Fetching GFS for 2024-01-29 18:00:00: 100%|██████████| 7/7 [00:00<00:00, 50.60it/s]
    2024-04-19 00:32:05.072 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:151 - Fetching GFS index file: 2024-01-30 00:00:00
    Fetching GFS for 2024-01-30 00:00:00:   0%|          | 0/7 [00:00<?, ?it/s]                                                                               2024-04-19 00:32:05.157 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:197 - Fetching GFS grib file for variable: t850 at 2024-01-30 00:00:00
    Fetching GFS for 2024-01-30 00:00:00:   0%|          | 0/7 [00:00<?, ?it/s]                                                                               2024-04-19 00:32:05.176 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:197 - Fetching GFS grib file for variable: z1000 at 2024-01-30 00:00:00
    Fetching GFS for 2024-01-30 00:00:00:   0%|          | 0/7 [00:00<?, ?it/s]                                                                               2024-04-19 00:32:05.195 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:197 - Fetching GFS grib file for variable: z700 at 2024-01-30 00:00:00
    Fetching GFS for 2024-01-30 00:00:00:   0%|          | 0/7 [00:00<?, ?it/s]                                                                               2024-04-19 00:32:05.214 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:197 - Fetching GFS grib file for variable: z500 at 2024-01-30 00:00:00
    Fetching GFS for 2024-01-30 00:00:00:   0%|          | 0/7 [00:00<?, ?it/s]                                                                               2024-04-19 00:32:05.232 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:197 - Fetching GFS grib file for variable: z300 at 2024-01-30 00:00:00
    Fetching GFS for 2024-01-30 00:00:00:   0%|          | 0/7 [00:00<?, ?it/s]                                                                               2024-04-19 00:32:05.251 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:197 - Fetching GFS grib file for variable: tcwv at 2024-01-30 00:00:00
    Fetching GFS for 2024-01-30 00:00:00:   0%|          | 0/7 [00:00<?, ?it/s]    Fetching GFS for 2024-01-30 00:00:00:  86%|████████▌ | 6/7 [00:00<00:00, 52.70it/s]                                                                                       2024-04-19 00:32:05.271 | DEBUG    | earth2studio.data.gfs:fetch_gfs_dataarray:197 - Fetching GFS grib file for variable: t2m at 2024-01-30 00:00:00
    Fetching GFS for 2024-01-30 00:00:00:  86%|████████▌ | 6/7 [00:00<00:00, 52.70it/s]    Fetching GFS for 2024-01-30 00:00:00: 100%|██████████| 7/7 [00:00<00:00, 52.64it/s]
    2024-04-19 00:32:05.320 | SUCCESS  | earth2studio.run:ensemble:177 - Fetched data from GFS
    2024-04-19 00:32:05.325 | INFO     | earth2studio.run:ensemble:196 - Starting 16 Member Ensemble Inference with             4 number of batches.
    Total Ensemble Batches:   0%|          | 0/4 [00:00<?, ?it/s]
    Running batch 0 inference:   0%|          | 0/49 [00:00<?, ?it/s]
    Running batch 0 inference:   8%|▊         | 4/49 [00:00<00:01, 27.19it/s]
    Running batch 0 inference:  14%|█▍        | 7/49 [00:00<00:01, 24.83it/s]
    Running batch 0 inference:  20%|██        | 10/49 [00:00<00:01, 21.12it/s]
    Running batch 0 inference:  27%|██▋       | 13/49 [00:00<00:01, 20.11it/s]
    Running batch 0 inference:  33%|███▎      | 16/49 [00:00<00:01, 18.44it/s]
    Running batch 0 inference:  37%|███▋      | 18/49 [00:00<00:01, 17.84it/s]
    Running batch 0 inference:  41%|████      | 20/49 [00:01<00:01, 17.15it/s]
    Running batch 0 inference:  45%|████▍     | 22/49 [00:01<00:01, 16.55it/s]
    Running batch 0 inference:  49%|████▉     | 24/49 [00:01<00:01, 16.16it/s]
    Running batch 0 inference:  53%|█████▎    | 26/49 [00:01<00:01, 15.76it/s]
    Running batch 0 inference:  57%|█████▋    | 28/49 [00:01<00:01, 15.32it/s]
    Running batch 0 inference:  61%|██████    | 30/49 [00:01<00:01, 15.20it/s]
    Running batch 0 inference:  65%|██████▌   | 32/49 [00:01<00:01, 14.65it/s]
    Running batch 0 inference:  69%|██████▉   | 34/49 [00:02<00:01, 14.20it/s]
    Running batch 0 inference:  73%|███████▎  | 36/49 [00:02<00:00, 13.81it/s]
    Running batch 0 inference:  78%|███████▊  | 38/49 [00:02<00:00, 13.60it/s]
    Running batch 0 inference:  82%|████████▏ | 40/49 [00:02<00:00, 12.93it/s]
    Running batch 0 inference:  86%|████████▌ | 42/49 [00:02<00:00, 12.44it/s]
    Running batch 0 inference:  90%|████████▉ | 44/49 [00:02<00:00, 12.29it/s]
    Running batch 0 inference:  94%|█████████▍| 46/49 [00:03<00:00, 12.15it/s]
    Running batch 0 inference:  98%|█████████▊| 48/49 [00:03<00:00, 11.81it/s]
                                                                                  Total Ensemble Batches:  25%|██▌       | 1/4 [00:03<00:09,  3.29s/it]
    Running batch 4 inference:   0%|          | 0/49 [00:00<?, ?it/s]
    Running batch 4 inference:   6%|▌         | 3/49 [00:00<00:01, 28.77it/s]
    Running batch 4 inference:  12%|█▏        | 6/49 [00:00<00:01, 22.09it/s]
    Running batch 4 inference:  18%|█▊        | 9/49 [00:00<00:01, 20.57it/s]
    Running batch 4 inference:  24%|██▍       | 12/49 [00:00<00:01, 19.76it/s]
    Running batch 4 inference:  31%|███       | 15/49 [00:00<00:01, 19.33it/s]
    Running batch 4 inference:  35%|███▍      | 17/49 [00:00<00:01, 18.37it/s]
    Running batch 4 inference:  39%|███▉      | 19/49 [00:00<00:01, 17.73it/s]
    Running batch 4 inference:  43%|████▎     | 21/49 [00:01<00:01, 17.57it/s]
    Running batch 4 inference:  47%|████▋     | 23/49 [00:01<00:01, 17.51it/s]
    Running batch 4 inference:  51%|█████     | 25/49 [00:01<00:01, 17.11it/s]
    Running batch 4 inference:  55%|█████▌    | 27/49 [00:01<00:01, 16.10it/s]
    Running batch 4 inference:  59%|█████▉    | 29/49 [00:01<00:01, 16.05it/s]
    Running batch 4 inference:  63%|██████▎   | 31/49 [00:01<00:01, 15.70it/s]
    Running batch 4 inference:  67%|██████▋   | 33/49 [00:01<00:01, 15.43it/s]
    Running batch 4 inference:  71%|███████▏  | 35/49 [00:02<00:00, 14.81it/s]
    Running batch 4 inference:  76%|███████▌  | 37/49 [00:02<00:00, 14.11it/s]
    Running batch 4 inference:  80%|███████▉  | 39/49 [00:02<00:00, 13.45it/s]
    Running batch 4 inference:  84%|████████▎ | 41/49 [00:02<00:00, 13.04it/s]
    Running batch 4 inference:  88%|████████▊ | 43/49 [00:02<00:00, 12.76it/s]
    Running batch 4 inference:  92%|█████████▏| 45/49 [00:02<00:00, 12.31it/s]
    Running batch 4 inference:  96%|█████████▌| 47/49 [00:03<00:00, 12.03it/s]
    Running batch 4 inference: 100%|██████████| 49/49 [00:03<00:00, 11.79it/s]
                                                                                  Total Ensemble Batches:  50%|█████     | 2/4 [00:06<00:06,  3.25s/it]
    Running batch 8 inference:   0%|          | 0/49 [00:00<?, ?it/s]
    Running batch 8 inference:   6%|▌         | 3/49 [00:00<00:01, 28.08it/s]
    Running batch 8 inference:  12%|█▏        | 6/49 [00:00<00:01, 22.50it/s]
    Running batch 8 inference:  18%|█▊        | 9/49 [00:00<00:01, 21.09it/s]
    Running batch 8 inference:  24%|██▍       | 12/49 [00:00<00:01, 19.16it/s]
    Running batch 8 inference:  29%|██▊       | 14/49 [00:00<00:01, 18.46it/s]
    Running batch 8 inference:  33%|███▎      | 16/49 [00:00<00:01, 17.78it/s]
    Running batch 8 inference:  37%|███▋      | 18/49 [00:00<00:01, 17.14it/s]
    Running batch 8 inference:  41%|████      | 20/49 [00:01<00:01, 16.59it/s]
    Running batch 8 inference:  45%|████▍     | 22/49 [00:01<00:01, 16.23it/s]
    Running batch 8 inference:  49%|████▉     | 24/49 [00:01<00:01, 15.78it/s]
    Running batch 8 inference:  53%|█████▎    | 26/49 [00:01<00:01, 15.22it/s]
    Running batch 8 inference:  57%|█████▋    | 28/49 [00:01<00:01, 14.78it/s]
    Running batch 8 inference:  61%|██████    | 30/49 [00:01<00:01, 14.69it/s]
    Running batch 8 inference:  65%|██████▌   | 32/49 [00:01<00:01, 14.43it/s]
    Running batch 8 inference:  69%|██████▉   | 34/49 [00:02<00:01, 14.10it/s]
    Running batch 8 inference:  73%|███████▎  | 36/49 [00:02<00:00, 13.84it/s]
    Running batch 8 inference:  78%|███████▊  | 38/49 [00:02<00:00, 13.48it/s]
    Running batch 8 inference:  82%|████████▏ | 40/49 [00:02<00:00, 12.93it/s]
    Running batch 8 inference:  86%|████████▌ | 42/49 [00:02<00:00, 12.80it/s]
    Running batch 8 inference:  90%|████████▉ | 44/49 [00:02<00:00, 12.41it/s]
    Running batch 8 inference:  94%|█████████▍| 46/49 [00:03<00:00, 12.21it/s]
    Running batch 8 inference:  98%|█████████▊| 48/49 [00:03<00:00, 11.99it/s]
                                                                                  Total Ensemble Batches:  75%|███████▌  | 3/4 [00:09<00:03,  3.29s/it]
    Running batch 12 inference:   0%|          | 0/49 [00:00<?, ?it/s]
    Running batch 12 inference:   6%|▌         | 3/49 [00:00<00:01, 29.48it/s]
    Running batch 12 inference:  12%|█▏        | 6/49 [00:00<00:01, 22.54it/s]
    Running batch 12 inference:  18%|█▊        | 9/49 [00:00<00:01, 21.39it/s]
    Running batch 12 inference:  24%|██▍       | 12/49 [00:00<00:01, 19.51it/s]
    Running batch 12 inference:  31%|███       | 15/49 [00:00<00:01, 19.16it/s]
    Running batch 12 inference:  35%|███▍      | 17/49 [00:00<00:01, 18.44it/s]
    Running batch 12 inference:  39%|███▉      | 19/49 [00:00<00:01, 17.93it/s]
    Running batch 12 inference:  43%|████▎     | 21/49 [00:01<00:01, 17.50it/s]
    Running batch 12 inference:  47%|████▋     | 23/49 [00:01<00:01, 17.06it/s]
    Running batch 12 inference:  51%|█████     | 25/49 [00:01<00:01, 16.90it/s]
    Running batch 12 inference:  55%|█████▌    | 27/49 [00:01<00:01, 16.28it/s]
    Running batch 12 inference:  59%|█████▉    | 29/49 [00:01<00:01, 15.94it/s]
    Running batch 12 inference:  63%|██████▎   | 31/49 [00:01<00:01, 15.20it/s]
    Running batch 12 inference:  67%|██████▋   | 33/49 [00:01<00:01, 14.50it/s]
    Running batch 12 inference:  71%|███████▏  | 35/49 [00:02<00:01, 13.90it/s]
    Running batch 12 inference:  76%|███████▌  | 37/49 [00:02<00:00, 13.65it/s]
    Running batch 12 inference:  80%|███████▉  | 39/49 [00:02<00:00, 13.45it/s]
    Running batch 12 inference:  84%|████████▎ | 41/49 [00:02<00:00, 12.99it/s]
    Running batch 12 inference:  88%|████████▊ | 43/49 [00:02<00:00, 12.61it/s]
    Running batch 12 inference:  92%|█████████▏| 45/49 [00:02<00:00, 12.44it/s]
    Running batch 12 inference:  96%|█████████▌| 47/49 [00:03<00:00, 12.14it/s]
    Running batch 12 inference: 100%|██████████| 49/49 [00:03<00:00, 11.88it/s]
                                                                                   Total Ensemble Batches: 100%|██████████| 4/4 [00:13<00:00,  3.27s/it]    Total Ensemble Batches: 100%|██████████| 4/4 [00:13<00:00,  3.27s/it]
    2024-04-19 00:32:18.425 | SUCCESS  | earth2studio.run:ensemble:242 - Ensemble Inference complete




.. GENERATED FROM PYTHON SOURCE LINES 174-181

Post Processing
---------------
The last step is to post process our results.
Here we plot and compare the ensemble mean and standard deviation from using an
unperturbed/perturbed model.

Notice that the Zarr IO function has additional APIs to interact with the stored data.

.. GENERATED FROM PYTHON SOURCE LINES 183-318

.. code-block:: Python

    import cartopy.crs as ccrs
    import matplotlib.pyplot as plt
    from matplotlib.colors import LogNorm

    levels_unperturbed = np.linspace(0, io_unperturbed["tcwv"][:].max())
    levels_perturbed = np.linspace(0, io_perturbed["tcwv"][:].max())


    std_levels_perturbed = np.linspace(0, io_perturbed["tcwv"][:].std(axis=0).max())

    plt.close("all")
    fig = plt.figure(figsize=(20, 10), tight_layout=True)
    ax0 = fig.add_subplot(2, 2, 1, projection=ccrs.PlateCarree())
    ax1 = fig.add_subplot(2, 2, 2, projection=ccrs.PlateCarree())
    ax2 = fig.add_subplot(2, 2, 3, projection=ccrs.PlateCarree())
    ax3 = fig.add_subplot(2, 2, 4, projection=ccrs.PlateCarree())


    def update(frame):
        """This function updates the frame with a new lead time for animation."""
        import warnings

        warnings.filterwarnings("ignore")
        ax0.clear()
        ax1.clear()
        ax2.clear()
        ax3.clear()

        ## Update unperturbed image
        im0 = ax0.contourf(
            io_unperturbed["lon"][:],
            io_unperturbed["lat"][:],
            io_unperturbed["tcwv"][:, 0, frame].mean(axis=0),
            transform=ccrs.PlateCarree(),
            cmap="Blues",
            levels=levels_unperturbed,
        )
        ax0.coastlines()
        ax0.gridlines()

        im1 = ax1.contourf(
            io_unperturbed["lon"][:],
            io_unperturbed["lat"][:],
            io_unperturbed["tcwv"][:, 0, frame].std(axis=0),
            transform=ccrs.PlateCarree(),
            cmap="RdPu",
            levels=std_levels_perturbed,
            norm=LogNorm(vmin=1e-1, vmax=std_levels_perturbed[-1]),
        )
        ax1.coastlines()
        ax1.gridlines()

        im2 = ax2.contourf(
            io_perturbed["lon"][:],
            io_perturbed["lat"][:],
            io_perturbed["tcwv"][:, 0, frame].mean(axis=0),
            transform=ccrs.PlateCarree(),
            cmap="Blues",
            levels=levels_perturbed,
        )
        ax2.coastlines()
        ax2.gridlines()

        im3 = ax3.contourf(
            io_perturbed["lon"][:],
            io_perturbed["lat"][:],
            io_perturbed["tcwv"][:, 0, frame].std(axis=0),
            transform=ccrs.PlateCarree(),
            cmap="RdPu",
            levels=std_levels_perturbed,
            norm=LogNorm(vmin=1e-1, vmax=std_levels_perturbed[-1]),
        )
        ax3.coastlines()
        ax3.gridlines()

        for i in range(16):
            ax0.contour(
                io_unperturbed["lon"][:],
                io_unperturbed["lat"][:],
                io_unperturbed["z500"][i, 0, frame] / 100.0,
                transform=ccrs.PlateCarree(),
                levels=np.arange(485, 580, 15),
                colors="black",
                linestyle="dashed",
            )

            ax2.contour(
                io_perturbed["lon"][:],
                io_perturbed["lat"][:],
                io_perturbed["z500"][i, 0, frame] / 100.0,
                transform=ccrs.PlateCarree(),
                levels=np.arange(485, 580, 15),
                colors="black",
                linestyle="dashed",
            )
        plt.suptitle(
            f'Forecast Starting on {forecast_date} - Lead Time - {io_perturbed["lead_time"][frame]}'
        )

        ax0.set_title("Unperturbed Ensemble Mean - tcwv + z500 countors")
        ax1.set_title("Unperturbed Ensemble Std - tcwv")
        ax2.set_title("Perturbed Ensemble Mean - tcwv + z500 contours")
        ax3.set_title("Perturbed Ensemble Std - tcwv")

        if frame == 0:
            plt.colorbar(
                im0, ax=ax0, shrink=0.75, pad=0.04, label="kg m^-2", format="%2.1f"
            )
            plt.colorbar(
                im1, ax=ax1, shrink=0.75, pad=0.04, label="kg m^-2", format="%1.2e"
            )
            plt.colorbar(
                im2, ax=ax2, shrink=0.75, pad=0.04, label="kg m^-2", format="%2.1f"
            )
            plt.colorbar(
                im3, ax=ax3, shrink=0.75, pad=0.04, label="kg m^-2", format="%1.2e"
            )


    # Uncomment this for animation
    # import matplotlib.animation as animation
    # update(0)
    # ani = animation.FuncAnimation(
    # fig=fig, func=update, frames=range(1, nsteps), cache_frame_data=False
    # )
    # ani.save(f"outputs/05_model_perturbation_{forecast_date}.gif", dpi=300)


    for lt in [10, 20, 30, 40]:
        update(lt)
        plt.savefig(
            f"outputs/05_model_perturbation_{forecast_date}_leadtime_{lt}.png",
            dpi=300,
            bbox_inches="tight",
        )



.. image-sg:: /examples/images/sphx_glr_05_model_perturbation_hook_001.png
   :alt: Forecast Starting on 2024-01-30 - Lead Time - 240 hours, Unperturbed Ensemble Mean - tcwv + z500 countors, Unperturbed Ensemble Std - tcwv, Perturbed Ensemble Mean - tcwv + z500 contours, Perturbed Ensemble Std - tcwv
   :srcset: /examples/images/sphx_glr_05_model_perturbation_hook_001.png, /examples/images/sphx_glr_05_model_perturbation_hook_001_2_00x.png 2.00x
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (1 minutes 18.509 seconds)


.. _sphx_glr_download_examples_05_model_perturbation_hook.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: 05_model_perturbation_hook.ipynb <05_model_perturbation_hook.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: 05_model_perturbation_hook.py <05_model_perturbation_hook.py>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
