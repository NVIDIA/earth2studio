{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Model Hook Injection: Perturbation\n\nAdding model noise by using custom hooks.\n\nThis example will demonstrate how to run a an ensemble inference workflow to generate a\nperturbed ensemble forecast. This perturbation is done by injecting code into the model\nfront and rear hooks. These hooks are applied to the tensor data before/after the model forward call.\n\nThis example also illustrates how you can subselect data for IO. In this example we will only output\ntwo variables: total column water vapour (tcwv) and 500 hPa geopotential (z500). To run this make\nsure that the model selected predicts these variables are change appropriately.\n\nIn this example you will learn:\n\n- How to instantiate a built in prognostic model\n- Creating a data source and IO object\n- Changing the model forward/rear hooks\n- Choose a subselection of coordinates to save to an IO object.\n- Post-processing results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating an Ensemble Workflow\n\nTo start lets begin with creating an ensemble workflow to use. We encourage\nusers to explore and experiment with their own custom workflows that borrow ideas from\nbuilt in workflows inside :py:obj:`earth2studio.run` or the examples.\n\nCreating our own generalizable ensemble workflow is easy when we rely on the component\ninterfaces defined in Earth2Studio (use dependency injection). Here we create a run\nmethod that accepts the following:\n\n- time: Input list of datetimes / strings to run inference for\n- nsteps: Number of forecast steps to predict\n- nensemble: Number of ensembles to run for\n- prognostic: Our initialized prognostic model\n- data: Initialized data source to fetch initial conditions from\n- io: io store that data is written to.\n- output_coords: CoordSystem of output coordinates that should be saved. Should be\n     a proper subset of model output coordinates.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\nfrom datetime import datetime\nfrom dotenv import load_dotenv\n\nload_dotenv()  # TODO: make common example prep function\n\nimport numpy as np\nimport torch\nfrom loguru import logger\nfrom tqdm import tqdm\n\nfrom earth2studio.data import DataSource, fetch_data\nfrom earth2studio.io import IOBackend\nfrom earth2studio.models.px import PrognosticModel\nfrom earth2studio.utils.coords import CoordSystem, map_coords, extract_coords\nfrom earth2studio.utils.time import to_time_array\n\nlogger.remove()\nlogger.add(lambda msg: tqdm.write(msg, end=\"\"), colorize=True)\n\n\ndef run_ensemble(\n    time: list[str] | list[datetime] | list[np.datetime64],\n    nsteps: int,\n    nensemble: int,\n    prognostic: PrognosticModel,\n    data: DataSource,\n    io: IOBackend,\n    output_coords: CoordSystem = OrderedDict({}),\n) -> IOBackend:\n    \"\"\"Ensemble workflow\n\n    Parameters\n    ----------\n    time : list[str] | list[datetime] | list[np.datetime64]\n        List of string, datetimes or np.datetime64\n    nsteps : int\n        Number of forecast steps\n    nensemble : int\n        Number of ensemble members to run inference for.\n    prognostic : PrognosticModel\n        Prognostic models\n    data : DataSource\n        Data source\n    io : IOBackend\n        IO object\n\n    Returns\n    -------\n    IOBackend\n        Output IO object\n    \"\"\"\n    logger.info(\"Running ensemble inference!\")\n\n    # Load model onto the device\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    logger.info(f\"Inference device: {device}\")\n    prognostic = prognostic.to(device)\n\n    # Fetch data from data source and load onto device\n    time = to_time_array(time)\n    x, coords = fetch_data(\n        source=data,\n        time=time,\n        lead_time=prognostic.input_coords[\"lead_time\"],\n        variable=prognostic.input_coords[\"variable\"],\n        device=device,\n    )\n    logger.success(f\"Fetched data from {data.__class__.__name__}\")\n\n    # Expand x, coords for ensemble\n    x = x.unsqueeze(0).repeat(nensemble, *([1] * x.ndim))\n    coords = {\"ensemble\": np.arange(nensemble)} | coords\n\n    # Set up IO backend with information from output_coords (if applicable).\n    total_coords = coords.copy()\n    total_coords[\"lead_time\"] = np.asarray(\n        [prognostic.output_coords[\"lead_time\"] * i for i in range(nsteps + 1)]\n    ).flatten()\n    for key, value in total_coords.items():\n        total_coords[key] = output_coords.get(key, value)\n\n    variables_to_save = total_coords.pop(\"variable\")\n    io.add_array(total_coords, variables_to_save)\n\n    # Map lat and lon if needed\n    x, coords = map_coords(x, coords, prognostic.input_coords)\n\n    # Create prognostic iterator\n    model = prognostic.create_iterator(x, coords)\n\n    logger.info(\"Inference starting!\")\n    with tqdm(total=nsteps + 1, desc=\"Running inference\") as pbar:\n        for step, (x, coords) in enumerate(model):\n            # Subselect domain/variables as indicated in output_coords\n            x, coords = map_coords(x, coords, output_coords)\n            io.write(*extract_coords(x, coords))\n            pbar.update(1)\n            if step == nsteps:\n                break\n\n    logger.success(\"Inference complete\")\n    return io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Up\nWith the ensemble workflow defined, we now need to create the indivdual components.\n\nWe need the following:\n\n- Prognostic Model: Use the built in DLWP model :py:class:`earth2studio.models.px.DLWP`.\n- Datasource: Pull data from the GFS data api :py:class:`earth2studio.data.GFS`.\n- IO Backend: Lets save the outputs into a Zarr store :py:class:`earth2studio.io.ZarrBackend`.\n\nWe will first run the ensemble workflow using an unmodified function, that is a model that has the\ndefault (identity) forward and rear hooks. Then we will define new hooks for the model and rerun the\ninference request.\n%%\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport torch\n\nfrom earth2studio.models.px import DLWP\nfrom earth2studio.data import GFS\nfrom earth2studio.io import ZarrBackend\n\n# Load the default model package which downloads the check point from NGC\npackage = DLWP.load_default_package()\nmodel = DLWP.load_model(package)\n\n# Create the data source\ndata = GFS()\n\n# Create the IO handler, store in memory\nchunks = {\"ensemble\": 1, \"time\": 1}\nio_unperturbed = ZarrBackend(file_name=\"outputs/ensemble.zarr\", chunks=chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Execute the Workflow\nWith all componments intialized, running the workflow is a single line of Python code.\nWorkflow will return the provided IO object back to the user, which can be used to\nthen post process. Some have additional APIs that can be handy for post-processing or\nsaving to file. Check the API docs for more information.\n\n%%\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "nsteps = 4 * 12\nnensemble = 16\nforecast_date = \"2024-01-30\"\noutput_coords = {\n    \"lat\": np.arange(25.0, 60.0, 0.25),\n    \"lon\": np.arange(230.0, 300.0, 0.25),\n    \"variable\": np.array([\"tcwv\", \"z500\"]),\n}\n\n# Forst run the unperturbed model forcast\nio_unperturbed = run_ensemble(\n    [forecast_date],\n    nsteps,\n    nensemble,\n    model,\n    data,\n    io_unperturbed,\n    output_coords=output_coords,\n)\n\n# Introduce slight model perturbation\n# front_hook / rear_hook map (x, coords) -> (x, coords)\nmodel.front_hook = lambda x, coords: (\n    x\n    - 0.05\n    * x.var(dim=0)\n    * (x - model.center.unsqueeze(-1))\n    / (model.scale.unsqueeze(-1)) ** 2\n    + 0.1 * (x - x.mean(dim=0)),\n    coords,\n)\n# Also could use model.rear_hook = ...\n\nio_perturbed = ZarrBackend(\n    file_name=\"outputs/ensemble_model_perturbation.zarr\", chunks=chunks\n)\nio_perturbed = run_ensemble(\n    [forecast_date],\n    nsteps,\n    nensemble,\n    model,\n    data,\n    io_perturbed,\n    output_coords=output_coords,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Post Processing\nThe last step is to post process our results. Cartopy is a greate library for plotting\nfields on projects of a sphere. Here we plot and compare the ensemble mean and standard\ndeviation from using a unperturbed/perturbed model.\n\nNotice that the Zarr IO function has additional APIs to interact with the stored data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport cartopy.crs as ccrs\nimport matplotlib.animation as animation\nfrom matplotlib.colors import LogNorm\n\n\nlevels_unperturbed = np.linspace(0, io_unperturbed[\"tcwv\"][:].max())\nlevels_perturbed = np.linspace(0, io_perturbed[\"tcwv\"][:].max())\n\nstd_levels_perturbed = np.linspace(0, io_perturbed[\"tcwv\"][:].std(axis=0).max())\n\nplt.close(\"all\")\nfig = plt.figure(figsize=(20, 10), tight_layout=True)\nax0 = fig.add_subplot(2, 2, 1, projection=ccrs.PlateCarree())\nax1 = fig.add_subplot(2, 2, 2, projection=ccrs.PlateCarree())\nax2 = fig.add_subplot(2, 2, 3, projection=ccrs.PlateCarree())\nax3 = fig.add_subplot(2, 2, 4, projection=ccrs.PlateCarree())\n\n\ndef update(frame):\n    \"\"\"This function updates the frame with a new lead time for animation.\"\"\"\n    ax0.clear()\n    ax1.clear()\n    ax2.clear()\n    ax3.clear()\n\n    ## Update unperturbed image\n    im0 = ax0.contourf(\n        io_unperturbed[\"lon\"][:],\n        io_unperturbed[\"lat\"][:],\n        io_unperturbed[\"tcwv\"][:, 0, frame].mean(axis=0),\n        transform=ccrs.PlateCarree(),\n        cmap=\"Blues\",\n        levels=levels_unperturbed,\n    )\n    ax0.coastlines()\n    ax0.gridlines()\n\n    im1 = ax1.contourf(\n        io_unperturbed[\"lon\"][:],\n        io_unperturbed[\"lat\"][:],\n        io_unperturbed[\"tcwv\"][:, 0, frame].std(axis=0),\n        transform=ccrs.PlateCarree(),\n        cmap=\"RdPu\",\n        levels=std_levels_perturbed,\n        norm=LogNorm(vmin=1e-1, vmax=std_levels_perturbed[-1]),\n    )\n    ax1.coastlines()\n    ax1.gridlines()\n\n    im2 = ax2.contourf(\n        io_perturbed[\"lon\"][:],\n        io_perturbed[\"lat\"][:],\n        io_perturbed[\"tcwv\"][:, 0, frame].mean(axis=0),\n        transform=ccrs.PlateCarree(),\n        cmap=\"Blues\",\n        levels=levels_perturbed,\n    )\n    ax2.coastlines()\n    ax2.gridlines()\n\n    im3 = ax3.contourf(\n        io_perturbed[\"lon\"][:],\n        io_perturbed[\"lat\"][:],\n        io_perturbed[\"tcwv\"][:, 0, frame].std(axis=0),\n        transform=ccrs.PlateCarree(),\n        cmap=\"RdPu\",\n        levels=std_levels_perturbed,\n        norm=LogNorm(vmin=1e-1, vmax=std_levels_perturbed[-1]),\n    )\n    ax3.coastlines()\n    ax3.gridlines()\n\n    for i in range(16):\n        ax0.contour(\n            io_unperturbed[\"lon\"][:],\n            io_unperturbed[\"lat\"][:],\n            io_unperturbed[\"z500\"][i, 0, frame] / 100.0,\n            transform=ccrs.PlateCarree(),\n            levels=np.arange(485, 580, 15),\n            colors=\"black\",\n            linestyle=\"dashed\",\n        )\n\n        ax2.contour(\n            io_perturbed[\"lon\"][:],\n            io_perturbed[\"lat\"][:],\n            io_perturbed[\"z500\"][i, 0, frame] / 100.0,\n            transform=ccrs.PlateCarree(),\n            levels=np.arange(485, 580, 15),\n            colors=\"black\",\n            linestyle=\"dashed\",\n        )\n    plt.suptitle(\n        f'Forecast Starting on {forecast_date} - Lead Time - {io_perturbed[\"lead_time\"][frame]}'\n    )\n\n    if frame == 0:\n        ax0.set_title(\"Unperturbed Ensemble Mean - tcwv + z500 countors\")\n        ax1.set_title(\"Unperturbed Ensemble Std - tcwv\")\n        ax2.set_title(\"Perturbed Ensemble Mean - tcwv + z500 contours\")\n        ax2.set_title(\"Perturbed Ensemble Std - tcwv\")\n\n        plt.colorbar(\n            im0, ax=ax0, shrink=0.75, pad=0.04, label=\"kg m^-2\", format=\"%2.1f\"\n        )\n        plt.colorbar(\n            im1, ax=ax1, shrink=0.75, pad=0.04, label=\"kg m^-2\", format=\"%1.2e\"\n        )\n        plt.colorbar(\n            im2, ax=ax2, shrink=0.75, pad=0.04, label=\"kg m^-2\", format=\"%2.1f\"\n        )\n        plt.colorbar(\n            im3, ax=ax3, shrink=0.75, pad=0.04, label=\"kg m^-2\", format=\"%1.2e\"\n        )\n\n\n# Uncomment this for animation\n# update(0)\n# ani = animation.FuncAnimation(\n# fig=fig, func=update, frames=range(1, nsteps), cache_frame_data=False\n# )\n# ani.save(f\"outputs/model_perturbation_{forecast_date}.gif\", dpi=300)\n\n# Here we plot a handful of images\nfor lt in [0, 10, 20, 30, 40]:\n    update(lt)\n    plt.savefig(\n        f\"outputs/model_perturbation_{forecast_date}_leadtime_{lt}.png\",\n        dpi=300,\n        bbox_inches=\"tight\",\n    )"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}