{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Extending Diagnostic Models\n\nImplementing a custom diagnostic model\n\nThis example will demonstrate how extend Earth2Studio by implementing a custom\ndiagnostic model and running it in a general workflow.\n\nIn this example you will learn:\n\n- API requirements of diagnostic models\n- Implementing a custom diagnostic model\n- Running this custom model in a workflow with built in prognostic\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom Diagnostic\nAs dicussed in the `diagnostic_model_userguide` section of the userguide,\nEarth2Studio defines a diagnostic model through a simple interface\n:py:class:`earth2studio.models.dx.base.Diagnostic Model`. This can be used to help\nguide the required APIs needed to successfully create our own model.\n\nIn this example, lets consider a simple diagnostic that converts the surface\ntemperature in Kelvin to Celcius to make it more readable for the average person.\n\nOur diagnostic model has a base class of :py:class:`torch.nn.Module` which allows us\nto get the required :py:obj:`to(device)` method for free.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n\nimport numpy as np\nimport torch\n\nfrom earth2studio.models.batch import batch_func\nfrom earth2studio.utils import handshake_coords, handshake_dim\nfrom earth2studio.utils.type import CoordSystem\n\n\nclass CustomDiagnostic(torch.nn.Module):\n    \"\"\"Custom dianostic model\"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    input_coords = OrderedDict(\n        {\n            \"batch\": np.empty(1),\n            \"variable\": np.array([\"t2m\"]),\n            \"lat\": np.linspace(90, -90, 721),\n            \"lon\": np.linspace(0, 360, 1440, endpoint=False),\n        }\n    )\n\n    output_coords = OrderedDict(\n        {\n            \"batch\": np.empty(1),\n            \"variable\": np.array([\"t2m_c\"]),\n            \"lat\": np.linspace(90, -90, 721),\n            \"lon\": np.linspace(0, 360, 1440, endpoint=False),\n        }\n    )\n\n    @batch_func()\n    def __call__(\n        self,\n        x: torch.Tensor,\n        coords: CoordSystem,\n    ) -> tuple[torch.Tensor, CoordSystem]:\n        \"\"\"Runs diagnostic model\n\n        Parameters\n        ----------\n        x : torch.Tensor\n            Input tensor\n        coords : CoordSystem\n            Input coordinate system\n        \"\"\"\n        for i, (key, value) in enumerate(self.input_coords.items()):\n            if key != \"batch\":\n                handshake_dim(coords, key, i)\n                handshake_coords(coords, self.input_coords, key)\n\n        out_coords = coords.copy()\n        out_coords[\"variable\"] = self.output_coords[\"variable\"]\n        out = x - 273.15  # To celcius\n\n        return out, out_coords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Input/Output Coordinates\nDefining the input/output coordinate systems is essential for any model in\nEarth2Studio since this how both the package and users can learn what type of data\nthe model expects. Have a look at `coordinates_userguide` for details on\ncoordinate system. For this diagnostic model, we simply define the input coordinates\nto be the global surface temperature specificed in\n:py:file:`earth2studio.lexicon.base.py`. The output is a custom variable\n:py:var:`t2m_c` that represents the temperature in Celcius.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### :py:func:`__call__` API\nThe call function is the main API of diagnostic models that have a tensor and\ncoordinate system as input/output. This function first validates that the coordinate\nsystem is correct. Then both the input data tensor and also coordinate system are\nupdated and returned.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>You may notice the :py:func:`batch_func` decorator, which is used to make batched\n  operations easier. For more details about this refer to the `batch_function_userguide`\n  section of the userguide.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Up\nWith the custom diagnostic model defined, its now easily usable in a workflow. Lets\ncreate our own simple diagnostic workflow based on the ones that exist already in\nEarth2Studio.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\nfrom typing import Optional\n\nimport numpy as np\nimport torch\nfrom loguru import logger\nfrom tqdm import tqdm\n\nfrom earth2studio.data import DataSource, fetch_data\nfrom earth2studio.io import IOBackend\nfrom earth2studio.models.px import PrognosticModel\nfrom earth2studio.models.dx import DiagnosticModel\nfrom earth2studio.utils.coords import extract_coords, map_coords\nfrom earth2studio.utils.time import to_time_array\n\n\ndef run(\n    time: list[str] | list[datetime] | list[np.datetime64],\n    nsteps: int,\n    prognostic: PrognosticModel,\n    diagnostic: DiagnosticModel,\n    data: DataSource,\n    io: IOBackend,\n    device: Optional[torch.device] = None,\n) -> IOBackend:\n    \"\"\"Simple diagnostic workflow\n\n    Parameters\n    ----------\n    time : list[str] | list[datetime] | list[np.datetime64]\n        List of string, datetimes or np.datetime64\n    nsteps : int\n        Number of forecast steps\n    prognostic : PrognosticModel\n        Prognostic models\n    data : DataSource\n        Data source\n    io : IOBackend\n        IO object\n    device : Optional[torch.device], optional\n        Device to run inference on, by default None\n\n    Returns\n    -------\n    IOBackend\n        Output IO object\n    \"\"\"\n    logger.info(\"Running diagnostic workflow!\")\n    # Load model onto the device\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    logger.info(f\"Inference device: {device}\")\n    prognostic = prognostic.to(device)\n    # Fetch data from data source and load onto device\n    time = to_time_array(time)\n    x, coords = fetch_data(\n        source=data,\n        time=time,\n        lead_time=prognostic.input_coords[\"lead_time\"],\n        variable=prognostic.input_coords[\"variable\"],\n        device=device,\n    )\n    logger.success(f\"Fetched data from {data.__class__.__name__}\")\n\n    # Set up IO backend\n    total_coords = prognostic.output_coords.copy()\n    del total_coords[\"batch\"]  # Unsafe if batch not supported\n    for key, value in total_coords.items():\n        if value.shape == 0:\n            del total_coords[key]\n    total_coords[\"time\"] = time\n    total_coords[\"lead_time\"] = np.asarray(\n        [prognostic.output_coords[\"lead_time\"] * i for i in range(nsteps + 1)]\n    ).flatten()\n    total_coords.move_to_end(\"lead_time\", last=False)\n    total_coords.move_to_end(\"time\", last=False)\n\n    for name, value in diagnostic.output_coords.items():\n        if name == \"batch\":\n            continue\n        total_coords[name] = value\n\n    var_names = total_coords.pop(\"variable\")\n    io.add_array(total_coords, var_names)\n\n    # Map lat and lon if needed\n    x, coords = map_coords(x, coords, prognostic.input_coords)\n    # Create prognostic iterator\n    model = prognostic.create_iterator(x, coords)\n\n    logger.info(\"Inference starting!\")\n    with tqdm(total=nsteps + 1, desc=\"Running inference\") as pbar:\n        for step, (x, coords) in enumerate(model):\n\n            # Run diagnostic\n            x, coords = map_coords(x, coords, diagnostic.input_coords)\n            x, coords = diagnostic(x, coords)\n\n            io.write(*extract_coords(x, coords))\n            pbar.update(1)\n            if step == nsteps:\n                break\n\n    logger.success(\"Inference complete\")\n    return io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets instantiate the components needed.\n\n- Prognostic Model: Use the built in DLWP model :py:class:`earth2studio.models.px.DLWP`.\n- Diagnostic Model: The custom diagnostic model defined above\n- Datasource: Pull data from the GFS data api :py:class:`earth2studio.data.GFS`.\n- IO Backend: Lets save the outputs into a Zarr store :py:class:`earth2studio.io.ZarrBackend`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom collections import OrderedDict\nfrom dotenv import load_dotenv\n\nload_dotenv()  # TODO: make common example prep function\n\nfrom earth2studio.models.px import DLWP\nfrom earth2studio.data import GFS\nfrom earth2studio.io import ZarrBackend\n\n# Load the default model package which downloads the check point from NGC\npackage = DLWP.load_default_package()\nmodel = DLWP.load_model(package)\n\n# Diagnostic model\ndiagnostic = CustomDiagnostic()\n\n# Create the data source\ndata = GFS()\n\n# Create the IO handler, store in memory\nio = ZarrBackend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Execute the Workflow\nRunning our workflow with a build in prognostic model and a custom diagnostic is as\nsimple as the following.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "nsteps = 20\nio = run([\"2024-01-01\"], nsteps, model, diagnostic, data, io)\n\nprint(io.root.tree())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Post Processing\nTo confirm that out prognostic model is working as expect, we should expect the fields\nto be progressively more noisy as time progresses.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n\nos.makedirs(\"outputs\", exist_ok=True)\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\nimport cartopy.crs as ccrs\n\nforecast = \"2024-01-01\"\nvariable = \"t2m_c\"\n\nplt.close(\"all\")\n\n# Create a figure and axes with the specified projection\nfig, ax = plt.subplots(\n    1,\n    5,\n    figsize=(12, 4),\n    subplot_kw={\"projection\": ccrs.Orthographic()},\n    constrained_layout=True,\n)\n\ntimes = io[\"lead_time\"].astype(\"timedelta64[h]\").astype(int)\nstep = 4  # 24hrs\nfor i, t in enumerate(range(0, 20, step)):\n\n    ctr = ax[i].contourf(\n        io[\"lon\"][:],\n        io[\"lat\"][:],\n        io[variable][0, t],\n        vmin=-10,\n        vmax=30,\n        transform=ccrs.PlateCarree(),\n        levels=20,\n        cmap=\"coolwarm\",\n    )\n    ax[i].set_title(f\"{times[t]}hrs\")\n    ax[i].coastlines()\n    ax[i].gridlines()\n\nplt.suptitle(f\"{variable} - {forecast}\")\n\ncbar = plt.cm.ScalarMappable(cmap=\"coolwarm\")\ncbar.set_array(io[variable][0, 0])\ncbar.set_clim(-10.0, 30)\ncbar = fig.colorbar(cbar, ax=ax[-1], orientation=\"vertical\", label=\"C\", shrink=0.8)\n\n\nplt.savefig(\"outputs/custom_diagnostic_dlwp_prediction.jpg\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}